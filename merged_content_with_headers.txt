Directory Tree / Dizin Ağacı:
========================
├── .env
├── .gitignore
├── README.md
├── api/
│   ├── __init__.py
│   ├── dependencies.py
│   └── schemas.py
├── app.py
├── config/
│   ├── __init__.py
│   ├── logger.py
│   └── settings.py
├── core/
│   ├── __init__.py
│   ├── api/
│   │   └── routers/
│   ├── auth/
│   ├── database/
│   │   ├── __init__.py
│   │   ├── crud.py
│   │   ├── db_connection.py
│   │   ├── models.py
│   │   └── session.py
│   ├── models/
│   │   ├── __init__.py
│   │   └── assistant.py
│   ├── processing/
│   ├── rag/
│   │   ├── __init__.py
│   │   ├── base_rag.py
│   │   ├── embedding_service.py
│   │   ├── llama_index.py
│   │   ├── rag_service.py
│   │   ├── simple_rag.py
│   │   └── vector_store.py
│   ├── schemas/
│   │   └── enums.py
│   ├── services/
│   │   ├── __init__.py
│   │   ├── base_model.py
│   │   ├── document_processing.py
│   │   ├── file_upload.py
│   │   ├── ollama_service.py
│   │   └── openai_service.py
│   └── utils/
├── frontend/
│   ├── app.js
│   ├── index.html
│   ├── js/
│   ├── static/
│   │   └── style.css
│   └── style.css
├── get-pip.py
├── logs/
│   ├── 2025-01-28.log
│   ├── 2025-01-29.log
│   ├── 2025-01-30.log
│   └── 2025-01-31.log
├── merged_content_with_headers.txt
├── models/
├── processed_documents/
│   ├── 08d123b0-9aaf-4282-854f-3a49844fe6e7.pdf
│   ├── 2982e1dc-6037-4050-bdbd-db5fbe5a0e9b.pdf
│   ├── 2d325009-e181-4ce6-8deb-749f8fb1397a.pdf
│   ├── 2df87099-5011-4b40-8977-a8526e31c33e.pdf
│   ├── 4bae14db-a08e-4c94-a958-b923bddea679.pdf
│   ├── 5579e960-74e9-46d4-bdab-abc49d8fcbf7.pdf
│   ├── 58670ac1-5b3f-49c5-871b-aec1f2a86ec5.pdf
│   ├── 5f2ae060-b332-4506-bb5e-ea96db5fe537.pdf
│   ├── 64f2cc8e-da34-4c48-8017-9be1fdaa93e6.pdf
│   ├── 6531a15c-b3b4-4d9a-b191-19cf33a2cb11.pdf
│   ├── 6f1a5866-ce7c-408d-a253-23a1af78992a.pdf
│   ├── a0182176-7f4f-46e2-88ec-2f1eb223bf8d.pdf
│   ├── aa32e8fe-ee14-4833-a3be-6471afdd4df8.pdf
│   ├── adc68c6c-7806-48ef-aa51-f4bdb6e6873a.pdf
│   ├── d26ea2df-2b05-42eb-aee3-ef5746a05eba.pdf
│   ├── d69be94d-b1b5-4df1-8378-0fd6c73951d6.pdf
│   ├── e4f2421a-ca7f-47d1-8786-c0661399d02a.pdf
│   ├── e6912368-e0ba-418a-9fe5-c49f185824bf.pdf
│   └── fe2bfaf4-74ff-440e-978e-7cc19b21c6a6.pdf
├── readfiles.py
├── repositories/
├── requirements.txt
├── routers/
│   ├── __init__.py
│   ├── assistants.py
│   ├── auth.py
│   ├── documents.py
│   └── rag.py
├── scripts/
│   ├── check_tables.py
│   ├── create_database.py
│   ├── recreate_tables.py
│   └── test_database.py
├── setup.py
├── temp/
│   ├── 05e1e83b-779e-44c7-b355-455b1f3c67ee.pdf
│   ├── 084f3d4b-af84-4c16-8d82-69d4383f3c2e.pdf
│   ├── 090e55e6-0052-4426-ae35-29d2f809bb45.pdf
│   ├── 10484036-a821-44e0-b374-1ff8f7b9fa18.pdf
│   ├── 117fd05c-ff7f-4adc-97b3-5a020f31d62a.pdf
│   ├── 175d83f1-acbf-4517-8f3f-ff4705da935d.pdf
│   ├── 24f57cbd-0899-4162-98e5-08189879f695.pdf
│   ├── 29465e7e-1217-42f4-a5a6-57595bbe7a9b.pdf
│   ├── 2af9b97c-2a5c-4049-a155-e88c6460d2d5.pdf
│   ├── 2e54faf5-f7e3-49ea-b983-978524729274.pdf
│   ├── 35ff0848-4c72-4974-8779-18edd65530df.pdf
│   ├── 36812d58-06fa-40e0-bf4b-eb10ebfc5647.pdf
│   ├── 38f699d8-effe-405d-88a3-8e613495d005.pdf
│   ├── 4b23df23-7d0e-4de7-bbd7-6953e2ea6858.pdf
│   ├── 4f414a79-68ca-4766-8190-1583b6e5bc9f.pdf
│   ├── 671143a9-3ab3-464f-8886-09c2f809ccac.pdf
│   ├── 71a2eba2-fcb9-408e-adec-d291cbaf3ef0.pdf
│   ├── 876c6feb-ae72-4ebf-821d-3a4f01a563d7.pdf
│   ├── 8bd51dc6-889e-41e1-bf54-42a6a58444ee.pdf
│   ├── 8e73fd4d-60c3-4895-9edb-9a55e0d1b279.pdf
│   ├── 92d257cd-b106-4b28-b2ed-6ae64b578878.pdf
│   ├── 9f9b3a9c-38a3-4179-8825-4712d4e438e7.pdf
│   ├── a1c92533-f827-464a-a388-e691b62c758d.pdf
│   ├── aa104e22-2ed4-4191-9dd2-c806ff121326.pdf
│   ├── aa49fe3d-556d-4476-8ee6-08091cb7c42f.pdf
│   ├── ab338533-a8ce-4122-a9c0-19eae81ed70e.pdf
│   ├── ac566dca-bfcc-43a7-b648-81f714d8d447.pdf
│   ├── b4dd4fb8-21f2-4c21-abb4-180e5fa74f4d.pdf
│   ├── b58347c4-745a-4327-bc9e-26e983c5e392.pdf
│   ├── b8fc6e5c-5aa4-4391-b772-8baae6c62b90.pdf
│   ├── bbfbe195-4a65-4654-878c-868ebc7b0854.pdf
│   ├── bebfae74-18c8-405c-acdb-ba648c7aef61.txt
│   ├── c3275488-4034-40a6-8708-1717e12eb2d9.pdf
│   ├── c35452ae-993e-431c-824d-b1c47cfb2aba.pdf
│   ├── ce61657c-b0b9-40e0-ba91-66d3009b617e.pdf
│   ├── d6d5c6c1-94c7-48a2-93a7-9c066398f703.pdf
│   ├── d94eb23f-2cb0-4f7b-bcf8-a4f1cefcbda2.pdf
│   ├── e68553c8-a68e-4232-b622-f06d7e482a96.pdf
│   ├── e8992bc1-0972-4833-b3a9-9dfc59c2215b.md
│   ├── e92a8975-6934-4ca7-82b6-814617614df5.pdf
│   ├── ec65127b-5f1c-4857-865d-46376788f2c6.pdf
│   ├── f1762e19-50b0-41ff-aa34-30d48707d31f.pdf
│   └── faf00dd0-cecd-49a7-8f85-be2359b5e2a5.pdf
├── test_api.py
├── test_core.py
├── test_multi_rag.py
└── utils/


File Contents / Dosya İçerikleri:
========================

Directory: C:\Users\Tuga-Munir\source\repos\chatbot_framework

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\app.py ====
# Path: chatbot_framework/app.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from routers import assistants_router, rag_router, documents_router,auth
from core.database import Base, engine
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, JSONResponse
from config.logger import app_logger

app = FastAPI()

# CORS ayarları
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["X-Conversation-Id"]  # Bu header'ın expose edildiğinden emin olun
)

# Frontend dosyalarını serve et
app.mount("/static", StaticFiles(directory="frontend"), name="static")

# Tabloları oluştur
@app.on_event("startup")
async def init_db():
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)

# Routerları ekle
app.include_router(auth.router)
app.include_router(assistants_router)
app.include_router(rag_router)
app.include_router(documents_router)

# Root endpoint - index.html'i serve et
@app.get("/")
async def root():
    return FileResponse("frontend/index.html")

# API root endpoint
@app.get("/api")
async def api_root():
    return {"message": "Welcome to AI Chat API"}

@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    app_logger.error(
        "Global hata: %s - URL: %s",
        str(exc),
        request.url.path,
        exc_info=True
    )
    return JSONResponse(
        status_code=500,
        content={"detail": "Internal server error"}
    )


==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\readfiles.py ====
import os

# === SETTINGS (Customize as needed) / AYARLAR (İsteğinize göre düzenleyin) ===

# Directory to scan / Tarayacağınız dizin
DIRECTORY_TO_SCAN = r"C:\Users\Tuga-Munir\source\repos\chatbot_framework"

# Folders to exclude / Hariç tutmak istediğiniz klasörler
IGNORED_DIRS = ["venv", ".git", "__pycache__",".venv"]

# Files to exclude / Hariç tutmak istediğiniz dosyalar
IGNORED_FILES = ["get-pip.py", ".gitignore"]

# Only files with these extensions will be read / Sadece bu uzantılara sahip dosyalar okunacak
FILE_EXTENSIONS = ["py", "html", "css", "js"]

# Full file path for saving the output / Çıktının kaydedileceği tam dosya yolu
OUTPUT_FILE = os.path.join(DIRECTORY_TO_SCAN, "merged_content_with_headers.txt")


def get_directory_tree(directory: str, prefix: str = "", ignored_dirs: list[str] = None) -> str:
    """
    Creates a tree structure of directories and files
    Dizin ve dosyaların ağaç yapısını oluşturur
    """
    if ignored_dirs is None:
        ignored_dirs = []
        
    tree = ""
    entries = os.listdir(directory)
    entries = [e for e in entries if e not in ignored_dirs]
    entries.sort()
    
    for i, entry in enumerate(entries):
        path = os.path.join(directory, entry)
        is_last = i == len(entries) - 1
        
        if os.path.isdir(path):
            tree += f"{prefix}{'└──' if is_last else '├──'} {entry}/\n"
            extension = "    " if is_last else "│   "
            tree += get_directory_tree(path, prefix + extension, ignored_dirs)
        else:
            tree += f"{prefix}{'└──' if is_last else '├──'} {entry}\n"
            
    return tree


def read_files_with_directory_headers(
    directory: str,
    extensions: list[str],
    ignored_dirs: list[str] = None,
    ignored_files: list[str] = None
) -> str:
    """
    Reads files in the specified directory and merges their content with directory information.
    Belirtilen dizindeki dosyaları okur ve dizin bilgisi ile birlikte içeriklerini birleştirir.

    :param directory: Directory to scan / Taranacak dizin.
    :param extensions: List of file extensions (e.g., ["py", "js"]) / Dosya uzantıları listesi (örn. ["py", "js"]).
    :param ignored_dirs: List of folders to exclude from scanning / Taranması istenmeyen klasörlerin listesi.
    :param ignored_files: List of files to completely ignore / Dosya adından tamamen kaçınılacak dosyaların listesi.
    :return: Returns the content as a single text / İçeriği tek bir metin olarak döndürür.
    """
    if ignored_dirs is None:
        ignored_dirs = []
    if ignored_files is None:
        ignored_files = []

    # First add directory tree / Önce dizin ağacını ekle
    all_content = "Directory Tree / Dizin Ağacı:\n"
    all_content += "========================\n"
    all_content += get_directory_tree(directory, ignored_dirs=ignored_dirs)
    all_content += "\n\nFile Contents / Dosya İçerikleri:\n"
    all_content += "========================\n\n"
    all_content += f"Directory: {directory}\n\n"

    for root, dirs, files in os.walk(directory):
        # Remove folders to be excluded / Hariç tutulması istenen klasörleri çıkar
        for d in ignored_dirs:
            if d in dirs:
                dirs.remove(d)

        for file in files:
            # Skip excluded files or files not in the extension list / Hariç tutulan dosyaları veya uzantı listesinde olmayanları atla
            if file in ignored_files or not file.endswith(tuple(extensions)):
                continue

            file_path = os.path.join(root, file)
            try:
                # File header / Dosya başlığı
                all_content += f"==== File: {file_path} ====\n"

                # Read file content / Dosya içeriğini oku
                with open(file_path, 'r', encoding='utf-8') as f:
                    all_content += f.read() + "\n\n"
            except Exception as e:
                print(f"Error reading file: {file_path}\nError: {e}\n")  # Error message / Hata mesajı

    return all_content


if __name__ == "__main__":
    # Read the content of all files / Tüm dosyaların içeriğini oku
    merged_content = read_files_with_directory_headers(
        DIRECTORY_TO_SCAN,
        FILE_EXTENSIONS,
        IGNORED_DIRS,
        IGNORED_FILES
    )

    # Save the content to the specified file / İçeriği belirlenen dosyaya kaydet
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write(merged_content)

    print(f"The content of all files with headers has been written to '{OUTPUT_FILE}'.")  # Success message / Başarı mesajı


==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\setup.py ====
from setuptools import setup, find_packages

setup(
    name="chatbot_framework",
    version="0.1",
    packages=find_packages(),
    install_requires=[
        "fastapi",
        "uvicorn",
        "python-dotenv",
        "openai",
        "httpx",
        "sse-starlette",
        "aiohttp",
        "sqlalchemy",
        "asyncpg",
        "alembic",
    ],
) 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\test_api.py ====
# Path: chatbot_framework/test_api.py
import asyncio
import httpx
import json
import aiohttp

async def test_api():
    base_url = "http://127.0.0.1:8000"
    
    async with httpx.AsyncClient(base_url=base_url, timeout=30.0) as client:
        try:
            # Asistan oluştur
            print("\n=== Creating OpenAI Assistant ===")
            create_data = {
                "name": "test_assistant",
                "model_type": "openai",
                "system_message": "You are a helpful assistant."
            }
            response = await client.post("/assistants/create", json=create_data)
            print(f"Create Response Status: {response.status_code}")
            print(f"Create Response: {response.json()}")

            # Asistanları listele
            print("\n=== Listing Assistants ===")
            response = await client.get("/assistants/list")
            print(f"List Response: {response.json()}")

            # Normal chat testi
            print("\n=== Testing Normal Chat ===")
            chat_data = {
                "message": "What is 2+2?",
                "stream": False
            }
            response = await client.post(
                "/assistants/test_assistant/chat",
                json=chat_data
            )
            print(f"Chat Response: {response.json()}")

            # Streaming chat testi
            print("\n=== Testing Streaming Chat ===")
            print("Streaming Response: ", end="", flush=True)
            
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    f"{base_url}/assistants/test_assistant/chat/stream",
                    params={"message": "Explain why the sky is blue in 3 sentences."}
                ) as response:
                    async for line in response.content:
                        if line:
                            try:
                                line = line.decode('utf-8').strip()
                                print(f"\nReceived line: {line}")
                                if line.startswith('data: '):
                                    data = line[6:]
                                    print(data, end="", flush=True)
                            except Exception as e:
                                print(f"\nError parsing SSE: {str(e)}")
            print("\nStreaming completed")

        except httpx.ConnectError as e:
            print(f"Connection Error: FastAPI server is not running at {base_url}")
            print("Please make sure to start the server with:")
            print("uvicorn app:app --reload")
            raise
        except Exception as e:
            print(f"Error during API test: {str(e)}")
            raise

if __name__ == "__main__":
    asyncio.run(test_api()) 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\test_core.py ====
# Path: chatbot_framework/test_core.py
import asyncio
import os
from dotenv import load_dotenv
from core.services.openai_service import OpenAIService
from core.services.ollama_service import OllamaService
from core.models.assistant import Assistant

async def test_assistants():
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("Warning: OPENAI_API_KEY not found in .env file")
    
    # OpenAI asistanını test et
    print("\n=== Testing OpenAI Assistant ===")
    try:
        openai_service = OpenAIService(api_key=api_key)
        openai_assistant = Assistant(
            name="OpenAI Assistant",
            model=openai_service,
            system_message="You are a helpful assistant."
        )
         
        # Normal yanıt testi
        print("\nTesting normal response:")
        response = await openai_assistant.process_message("merhaba nasılsın")
        print(f"OpenAI Response: {response}")
        
        # Streaming yanıt testi
        print("\nTesting streaming response:")
        print("OpenAI Streaming Response: ", end="", flush=True)
        async for token in await openai_assistant.process_message(
            "merhaba nasılsın", 
            stream=True
        ):
            print(token, end="", flush=True)
        print()  # Yeni satır
        
    except Exception as e:
        print(f"OpenAI Test Error: {str(e)}")
        import traceback
        print(traceback.format_exc())

    # Ollama asistanını test et
    print("\n=== Testing Ollama Assistant ===")
    try:
        ollama_service = OllamaService(model="llama3.2")
        ollama_assistant = Assistant(
            name="Ollama Assistant",
            model=ollama_service,
            system_message="You are a helpful assistant."
        )
        
        # Normal yanıt testi
        print("\nTesting normal response:")
        response = await ollama_assistant.process_message("merhaba nasılsıns")
        print(f"Ollama Response: {response}")
        
        # Streaming yanıt testi
        print("\nTesting streaming response:")
        print("Ollama Streaming Response: ", end="", flush=True)
        async for token in await ollama_assistant.process_message(
            "merhaba nasılsın", 
            stream=True
        ):
            print(token, end="", flush=True)
        print()  # Yeni satır
        
    except Exception as e:
        print(f"Ollama Test Error: {str(e)}")
        import traceback
        print(traceback.format_exc())

if __name__ == "__main__":
    asyncio.run(test_assistants()) 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\test_multi_rag.py ====
import asyncio
import os
from dotenv import load_dotenv
from core.services.openai_service import OpenAIService
from core.services.ollama_service import OllamaService
from core.models.assistant import Assistant
from core.rag.simple_rag import SimpleRAG

async def test_multi_rag():
    # .env dosyasından API anahtarını yükle
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    
    # Test için örnek dökümanlar
    company_docs = {
        "mission": "Our company mission is to create innovative AI solutions.",
        "products": "We offer chatbot and RAG solutions.",
        "team": "Our team consists of AI researchers and engineers."
    }
    
    technical_docs = {
        "architecture": "The system uses a microservices architecture.",
        "deployment": "We use Docker and Kubernetes for deployment.",
        "api": "REST API documentation includes authentication details."
    }
    
    knowledge_base = {
        "faq": "Common questions about our services and support.",
        "pricing": "Our services start from $99 per month.",
        "contact": "You can reach us at support@example.com"
    }

    try:
        # RAG sistemlerini oluştur
        company_rag = SimpleRAG("Company Info", company_docs)
        tech_rag = SimpleRAG("Technical Docs", technical_docs)
        kb_rag = SimpleRAG("Knowledge Base", knowledge_base)

        # OpenAI asistanını oluştur
        print("\n=== Creating Multi-RAG Assistant ===")
        assistant = Assistant(
            name="Multi-RAG Assistant",
            model=OpenAIService(api_key=api_key),
            system_message="You are a helpful assistant with access to multiple knowledge bases."
        )

        # RAG sistemlerini ekle
        assistant.add_rag_system(company_rag, "Company", weight=1.0)
        assistant.add_rag_system(tech_rag, "Technical", weight=0.8)
        assistant.add_rag_system(kb_rag, "Knowledge Base", weight=0.6)

        # Test senaryoları
        test_questions = [
            "What is our company's mission?",
            "How do we deploy our services?",
            "What are our pricing options?",
            "Tell me about our team and architecture.",  # Bu soru birden fazla RAG'i tetikleyecek
        ]

        for question in test_questions:
            print(f"\n\n=== Testing Question: {question} ===")
            
            # Normal yanıt testi
            print("\nNormal Response:")
            response = await assistant.process_message(question)
            print(response)
            
            # Streaming yanıt testi
            print("\nStreaming Response:", end=" ", flush=True)
            async for token in await assistant.process_message(question, stream=True):
                print(token, end="", flush=True)
            print()  # Yeni satır

            # RAG sistemini devre dışı bırakma testi
            print("\n=== Testing with disabled RAG ===")
            assistant.disable_rag_system("Technical")
            response = await assistant.process_message(question)
            print(response)
            
            # RAG sistemini tekrar etkinleştir
            assistant.enable_rag_system("Technical")

        # Konuşma geçmişini kontrol et
        print("\n=== Conversation History ===")
        for entry in assistant.conversation_history:
            print(f"\nUser: {entry['user']}")
            print(f"Assistant: {entry['assistant']}")
            if entry.get('rag_results'):
                print("RAG Results:", entry['rag_results'])

    except Exception as e:
        print(f"Test Error: {str(e)}")
        import traceback
        print(traceback.format_exc())

if __name__ == "__main__":
    asyncio.run(test_multi_rag()) 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\api\dependencies.py ====
from typing import Dict
from core.models.assistant import Assistant
from fastapi import HTTPException, Depends
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from core.database import get_db
from core.database.models import User
import uuid

# Global assistants dictionary
assistants: Dict[str, Assistant] = {}

def get_assistant(name: str) -> Assistant:
    """Get assistant by name or raise 404"""
    if name not in assistants:
        raise HTTPException(status_code=404, detail="Assistant not found")
    return assistants[name] 

# Auth router'ındaki gerçek current_user fonksiyonunu import ediyoruz
from routers.auth import get_current_user

# Bağımlılığı gerçek auth sistemine yönlendiriyoruz
get_current_user = get_current_user 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\api\schemas.py ====
from pydantic import BaseModel, EmailStr
from typing import Dict, Any, Optional, List
from datetime import datetime

class UserBase(BaseModel):
    email: EmailStr
    username: str

class UserCreate(UserBase):
    password: str

class UserResponse(UserBase):
    id: str
    created_at: datetime
    hashed_password: Optional[str] = None

    class Config:
        from_attributes = True

class Token(BaseModel):
    access_token: str
    token_type: str

class AssistantCreate(BaseModel):
    name: str
    model_type: str  # "openai" veya "ollama"
    model_name: str  # "gpt-4", "llama2" gibi
    system_message: str
    config: dict = {}

class AssistantResponse(BaseModel):
    id: str
    name: str
    model_type: str
    system_message: str
    config: Optional[Dict] = {}
    created_at: datetime
    updated_at: Optional[datetime] = None
    creator_id: Optional[str] = None

    class Config:
        from_attributes = True

class MessageResponse(BaseModel):
    id: str
    conversation_id: str
    role: str
    content: str
    created_at: datetime

    class Config:
        from_attributes = True

class ConversationResponse(BaseModel):
    id: str
    name: str
    assistant_id: str
    assistant_name: str
    session_id: str
    user_id: str
    created_at: datetime
    messages: List[MessageResponse] = []

    class Config:
        from_attributes = True

class RAGConfig(BaseModel):
    collection_name: str
    embedding_model: str
    chunk_size: int = 1000
    chunk_overlap: int = 200

class RAGDocumentBase(BaseModel):
    title: str
    content: str
    meta_data: Optional[Dict[str, Any]] = None

class RAGDocumentCreate(RAGDocumentBase):
    pass

class RAGDocumentResponse(RAGDocumentBase):
    id: str
    user_id: str
    created_at: datetime
    updated_at: datetime

    class Config:
        from_attributes = True

class RAGCollectionBase(BaseModel):
    name: str
    description: Optional[str] = None

class RAGCollectionCreate(RAGCollectionBase):
    pass

class RAGCollectionResponse(RAGCollectionBase):
    id: str
    user_id: str
    created_at: datetime
    updated_at: datetime

    class Config:
        from_attributes = True 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\api\__init__.py ====
from .schemas import *
from .dependencies import * 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\config\logger.py ====
import logging
from pathlib import Path
from datetime import datetime
import sys

# Log klasörünü oluştur
LOG_DIR = Path("logs")
LOG_DIR.mkdir(exist_ok=True)

# Log formatı
FORMATTER = logging.Formatter(
    "%(asctime)s — %(name)s — %(levelname)s — %(message)s"
)

# Temel logger konfigürasyonu
def setup_logger(name, level=logging.INFO):
    logger = logging.getLogger(name)
    logger.setLevel(level)

    # Konsol çıktısı
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(FORMATTER)
    
    # Dosya çıktısı
    file_handler = logging.FileHandler(
        LOG_DIR / f"{datetime.now().strftime('%Y-%m-%d')}.log"
    )
    file_handler.setFormatter(FORMATTER)

    logger.addHandler(console_handler)
    logger.addHandler(file_handler)
    return logger

# Uygulama geneli logger
app_logger = setup_logger("chatbot_app")


==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\config\settings.py ====


==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\config\__init__.py ====


==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\__init__.py ====


==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\database\crud.py ====
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from typing import Optional, List, Dict, Any
from .models import Assistant as DBAssistant, Assistant  # Add Assistant here
from .models import Conversation, Message, RAGDocument
from datetime import datetime
import hashlib
from core.schemas.enums import ProcessingStatus, FileType  # Add this import

class AssistantDB:
    @staticmethod
    async def create(
        db: AsyncSession,
        name: str,
        model_type: str,
        model_name: str,
        system_message: Optional[str] = None,
        config: Optional[Dict[str, Any]] = None
    ) -> DBAssistant:
        db_assistant = DBAssistant(
            name=name,
            model_type=model_type,
            model_name=model_name,
            system_message=system_message,
            config=config
        )
        db.add(db_assistant)
        await db.commit()
        await db.refresh(db_assistant)
        return db_assistant

    @staticmethod
    async def get_by_name(db: AsyncSession, name: str) -> Optional[DBAssistant]:
        result = await db.execute(
            select(DBAssistant).where(DBAssistant.name == name)
        )
        return result.scalar_one_or_none()

    @staticmethod
    async def list_all(db: AsyncSession) -> List[DBAssistant]:
        result = await db.execute(select(DBAssistant))
        return result.scalars().all()

class ConversationDB:
    @staticmethod
    async def create(
        db: AsyncSession,
        assistant_id: str,
        session_id: str,
        user_id: Optional[str] = None
    ) -> Conversation:
        conversation = Conversation(
            assistant_id=assistant_id,
            session_id=session_id,
            user_id=user_id
        )
        db.add(conversation)
        await db.commit()
        await db.refresh(conversation)
        return conversation

    @staticmethod
    async def add_message(
        db: AsyncSession,
        conversation_id: str,
        role: str,
        content: str,
        #rag_results: Optional[List[Dict[str, Any]]] = None
    ) -> Message:
        message = Message(
            conversation_id=conversation_id,
            role=role,
            content=content
        )
        db.add(message)
        await db.commit()
        
        #if rag_results:
            # RAGResult tablosu mevcut değil, bu kısmı kaldırıyoruz
            # for result in rag_results:
            #     rag_result = RAGResult(
            #         message_id=message.id,
            #         rag_system_id=result["system_id"],
            #         context=result["context"],
            #         metadata=result.get("metadata")
            #     )
            #     db.add(rag_result)
            #await db.commit()
        
        return message

    @staticmethod
    async def get_conversation_history(
        db: AsyncSession,
        session_id: str,
        limit: int = 100
    ) -> List[Dict[str, Any]]:
        result = await db.execute(
            select(Message)
            .join(Conversation)
            .where(Conversation.session_id == session_id)
            .order_by(Message.created_at)
            .limit(limit)
        )
        messages = result.scalars().all()
        
        history = []
        for msg in messages:
            rag_data = []
            for rag_result in msg.rag_results:
                rag_data.append({
                    "system_id": rag_result.rag_system_id,
                    "context": rag_result.context,
                    "metadata": rag_result.metadata
                })
            
            history.append({
                "role": msg.role,
                "content": msg.content,
                "created_at": msg.created_at,
                "rag_results": rag_data
            })
        
        return history 

async def create_rag_document(db: AsyncSession, document_data: dict):
    """Var olan metodun güncellenmiş hali"""
    # Zorunlu alanlar için default değerler
    default_values = {
        "content": "",
        "processing_status": ProcessingStatus.pending,
        "file_type": FileType.unknown,
        "created_at": datetime.utcnow(),
        "updated_at": datetime.utcnow(),
        "file_checksum": hashlib.sha256().hexdigest()[:64],  # Boş dosya için default checksum
        "chunk_size": 1000  # Default chunk size
    }
    
    # Mevcut veriyle default'ları birleştir
    final_data = {**default_values, **document_data}
    
    # Veritabanı constraint'lerine uygun hale getir
    rag_doc = RAGDocument(**final_data)
    
    db.add(rag_doc)
    await db.commit()
    await db.refresh(rag_doc)
    return rag_doc

async def create_assistant(db: AsyncSession, assistant_data: dict):
    """Yeni eklenen metod"""
    assistant = Assistant(
        name=assistant_data["name"],
        model_type=assistant_data["model_type"],
        system_message=assistant_data.get("system_message", ""),
        config=assistant_data.get("config", {}),
        creator_id=assistant_data["creator_id"],
        model_name=assistant_data.get("model_name", "gpt-3.5-turbo"),
        created_at=datetime.utcnow(),
        updated_at=datetime.utcnow()
    )
    db.add(assistant)
    await db.commit()
    await db.refresh(assistant)
    return assistant

async def update_rag_document_partial(db: AsyncSession, doc_id: str, updates: dict):
    """Var olan update metodunu bozmayan yeni versiyon"""
    doc = await db.get(RAGDocument, doc_id)
    if not doc:
        return None
    
    for key, value in updates.items():
        if hasattr(doc, key):
            setattr(doc, key, value)
    
    doc.updated_at = datetime.utcnow()
    await db.commit()
    await db.refresh(doc)
    return doc 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\database\db_connection.py ====
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import declarative_base
from sqlalchemy.orm import sessionmaker
import os
from dotenv import load_dotenv

load_dotenv()

# PostgreSQL bağlantı bilgileri
DB_USER = os.getenv("DB_USER", "postgres")
DB_PASSWORD = os.getenv("DB_PASSWORD", "your_password")
DB_HOST = os.getenv("DB_HOST", "localhost")
DB_PORT = os.getenv("DB_PORT", "5432")
DB_NAME = os.getenv("DB_NAME", "chatbot_db")

# Async database URL
DATABASE_URL = f"postgresql+asyncpg://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"

# Engine oluştur
engine = create_async_engine(
    DATABASE_URL,
    echo=True,  # SQL loglarını görmek için
)

# Session factory
async_session = sessionmaker(
    engine, class_=AsyncSession, expire_on_commit=False
)

# Base class for models
Base = declarative_base()

# Dependency
async def get_db():
    async with async_session() as session:
        try:
            yield session
        finally:
            await session.close()

__all__ = ['Base', 'get_db', 'engine', 'async_session']


==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\database\models.py ====
from sqlalchemy import Column, Integer, String, Text, ForeignKey, DateTime, JSON, LargeBinary
from sqlalchemy.orm import relationship, deferred
from datetime import datetime
from .db_connection import Base
import uuid
from sqlalchemy.types import Enum
from core.schemas.enums import ProcessingStatus, FileType

class User(Base):
    __tablename__ = "users"

    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    email = Column(String, unique=True, index=True)
    username = Column(String, unique=True)
    hashed_password = Column(String)
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relationships
    assistants = relationship("Assistant", back_populates="creator")
    conversations = relationship("Conversation", back_populates="user")
    rag_documents = relationship("RAGDocument", back_populates="user")
    rag_collections = relationship("RAGCollection", back_populates="user")

class Assistant(Base):
    __tablename__ = "assistants"

    id = Column(String, primary_key=True, index=True)
    name = Column(String, unique=True)
    model_type = Column(String)
    model_name = Column(String)
    system_message = Column(String)
    config = Column(JSON, default={})
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, onupdate=datetime.utcnow)
    creator_id = Column(String, ForeignKey("users.id"))
    
    # Relationships
    creator = relationship("User", back_populates="assistants")
    conversations = relationship("Conversation", back_populates="assistant")

class Conversation(Base):
    __tablename__ = "conversations"

    id = Column(String, primary_key=True, index=True)
    name = Column(String, nullable=False)
    assistant_id = Column(String, ForeignKey("assistants.id"))
    session_id = Column(String)
    user_id = Column(String, ForeignKey("users.id"))
    created_at = Column(DateTime)
    
    # Relationships
    assistant = relationship("Assistant", back_populates="conversations")
    user = relationship("User", back_populates="conversations")
    messages = relationship("Message", back_populates="conversation")

class Message(Base):
    __tablename__ = "messages"

    id = Column(String, primary_key=True, index=True)
    conversation_id = Column(String, ForeignKey("conversations.id"))
    role = Column(String)
    content = Column(Text)
    created_at = Column(DateTime)
    
    # Relationship
    conversation = relationship("Conversation", back_populates="messages")

class RAGDocument(Base):
    __tablename__ = "rag_documents"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    title = Column(String(255))
    content = Column(Text)
    file_path = Column(String(500))
    file_checksum = Column(String(64))
    file_size = Column(Integer)
    chunk_size = Column(Integer)
    processing_status = Column(
        Enum(ProcessingStatus, name="processing_status_enum"),
        default=ProcessingStatus.pending
    )
    embeddings = Column(LargeBinary)
    meta_data = Column(JSON)
    user_id = Column(String, ForeignKey("users.id"))
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    file_type = Column(
        Enum(FileType, name="file_type_enum"),
        default=FileType.unknown
    )
    embedding_model = Column(String)
    chunking_method = Column(String)
    processing_errors = Column(Text)
    
    user = relationship("User", back_populates="rag_documents")
    collections = relationship(
        "RAGCollection",
        secondary="rag_document_collections",
        back_populates="documents"
    )

class RAGCollection(Base):
    __tablename__ = "rag_collections"

    id = Column(String, primary_key=True, index=True)
    name = Column(String, nullable=False)
    description = Column(Text)
    user_id = Column(String, ForeignKey("users.id"))
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow)

    # Relationships
    user = relationship("User", back_populates="rag_collections")
    documents = relationship(
        "RAGDocument",
        secondary="rag_document_collections",
        back_populates="collections"
    )

class RAGDocumentCollection(Base):
    __tablename__ = "rag_document_collections"

    document_id = Column(String, ForeignKey("rag_documents.id"), primary_key=True)
    collection_id = Column(String, ForeignKey("rag_collections.id"), primary_key=True) 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\database\session.py ====
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker, declarative_base
from sqlalchemy import text
from dotenv import load_dotenv
import os

# .env dosyasını yükle
load_dotenv()

# Veritabanı bilgilerini .env'den al
DB_USER = os.getenv("DB_USER", "postgres")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_HOST = os.getenv("DB_HOST", "localhost")
DB_PORT = os.getenv("DB_PORT", "5432")
DB_NAME = os.getenv("DB_NAME", "chatbot_db")

# Database URL
DATABASE_URL = f"postgresql+asyncpg://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"

# Engine oluştur
engine = create_async_engine(DATABASE_URL, echo=True)

# Session factory
AsyncSessionLocal = sessionmaker(
    engine,
    class_=AsyncSession,
    expire_on_commit=False
)

# Base class for models
Base = declarative_base()

# Dependency to get DB session
async def get_db():
    async with AsyncSessionLocal() as session:
        try:
            yield session
        finally:
            await session.close()

async def init_db():
    """Veritabanı tablolarını oluştur"""
    print(f"Connecting to database at: {DB_HOST}:{DB_PORT}/{DB_NAME}")
    async with engine.begin() as conn:
        # Tüm tabloları oluştur
        await conn.run_sync(Base.metadata.create_all)
    
    print("Database tables created successfully!")

__all__ = ['Base', 'get_db', 'engine', 'AsyncSessionLocal', 'init_db'] 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\database\__init__.py ====
from .db_connection import Base, get_db, engine, async_session
from .session import AsyncSessionLocal
from .models import (
    User,
    Assistant,
    Conversation,
    Message,
    RAGDocument,
    RAGCollection,
    RAGDocumentCollection
)

__all__ = [
    'Base', 
    'get_db', 
    'engine', 
    'async_session',
    'AsyncSessionLocal',
    'Assistant',
    'Conversation',
    'Message',
    'User',
    'RAGDocument',
    'RAGCollection',
    'RAGDocumentCollection'
]



==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\models\assistant.py ====
# Path: chatbot_framework/core/models/assistant.py

from typing import AsyncIterator, Optional, Dict, Any
import json

class Assistant:
    def __init__(self, name: str, model, system_message: Optional[str] = None, config: Optional[Dict[str, Any]] = None):
        self.name = name
        self.model = model
        self.system_message = system_message
        self.config = config or {}
        self.rag_systems = []

    async def process_message(self, message: str, stream: bool = False) -> AsyncIterator[str]:
        try:
            if stream:
                async for chunk in self.model.chat_stream(message, self.system_message):
                    yield chunk
            else:
                response = await self.model.chat(message, self.system_message)
                yield response
                
        except Exception as e:
            print(f"Error in process_message: {str(e)}")
            yield f"Error: {str(e)}"

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\models\__init__.py ====
# TÜM İÇERİĞİ SİLİYORUZ, BOŞ BIRAKIYORUZ


==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\rag\base_rag.py ====
# Path: chatbot_framework/core/rag/base_rag.py
from abc import ABC, abstractmethod
from typing import List, Dict, Any

class BaseRAG(ABC):
    """RAG sistemleri için temel sınıf"""
    
    @abstractmethod
    async def add_documents(self, documents: List[Dict[str, Any]]) -> None:
        """Dökümanları indexe ekle"""
        pass

    @abstractmethod
    async def query(self, question: str) -> Dict[str, Any]:
        """Soru sorma ve ilgili dökümanları getirme"""
        pass

    @abstractmethod
    async def update_index(self) -> None:
        """Index'i güncelle"""
        pass 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\rag\embedding_service.py ====
from typing import List, Optional
import numpy as np
from openai import AsyncOpenAI
import tiktoken
from tenacity import retry, stop_after_attempt, wait_exponential
from config.settings import settings

class EmbeddingService:
    def __init__(self, api_key: Optional[str] = None, model: str = None):
        """
        Embedding servisi için yapılandırıcı.
        
        Args:
            api_key: OpenAI API anahtarı (None ise settings'den alınır)
            model: Kullanılacak embedding modeli (None ise settings'den alınır)
        """
        self.client = AsyncOpenAI(api_key=api_key or settings.OPENAI_API_KEY)
        self.model = model or settings.EMBEDDING_MODEL
        self.tokenizer = tiktoken.get_encoding("cl100k_base")
        
    def chunk_text(self, text: str, chunk_size: int = None, overlap: int = None) -> List[str]:
        """
        Metni belirli uzunlukta parçalara böler.
        
        Args:
            text: Bölünecek metin
            chunk_size: Parça boyutu (None ise settings'den alınır)
            overlap: Parçalar arası örtüşme miktarı (None ise settings'den alınır)
        """
        chunk_size = chunk_size or settings.CHUNK_SIZE
        overlap = overlap or settings.CHUNK_OVERLAP
        
        tokens = self.tokenizer.encode(text)
        chunks = []
        
        i = 0
        while i < len(tokens):
            # Parça boyutu kadar token al
            chunk_tokens = tokens[i:i + chunk_size]
            # Token'ları metne çevir
            chunk_text = self.tokenizer.decode(chunk_tokens)
            chunks.append(chunk_text)
            # Örtüşme miktarı kadar geri git
            i += chunk_size - overlap
            
        return chunks

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    async def get_embeddings(self, texts: List[str]) -> List[List[float]]:
        """
        Metinler için embedding'ler üretir.
        
        Args:
            texts: Embedding'i alınacak metinler listesi
            
        Returns:
            List[List[float]]: Embedding vektörleri listesi
        """
        try:
            response = await self.client.embeddings.create(
                model=self.model,
                input=texts
            )
            return [data.embedding for data in response.data]
        except Exception as e:
            print(f"Error in get_embeddings: {str(e)}")
            raise

    async def get_embedding(self, text: str) -> List[float]:
        """
        Tek bir metin için embedding üretir.
        
        Args:
            text: Embedding'i alınacak metin
            
        Returns:
            List[float]: Embedding vektörü
        """
        embeddings = await self.get_embeddings([text])
        return embeddings[0]

    def calculate_similarity(self, embedding1: List[float], embedding2: List[float]) -> float:
        """
        İki embedding vektörü arasındaki kosinüs benzerliğini hesaplar.
        
        Args:
            embedding1: İlk embedding vektörü
            embedding2: İkinci embedding vektörü
            
        Returns:
            float: Kosinüs benzerlik skoru (0-1 arası)
        """
        vec1 = np.array(embedding1)
        vec2 = np.array(embedding2)
        
        similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
        return float(similarity) 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\rag\llama_index.py ====


==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\rag\rag_service.py ====
from typing import List, Dict, Any
from .embedding_service import EmbeddingService
from .vector_store import get_vector_store
from config.settings import settings

class RAGService:
    def __init__(self):
        self.embedding_service = EmbeddingService()
        self.vector_store = get_vector_store()
        
    async def add_documents(self, documents: List[Dict[str, Any]]):
        """
        Dökümanları işle ve vector store'a ekle
        
        Args:
            documents: Her biri {'text': str, 'metadata': dict} formatında döküman listesi
        """
        texts = [doc['text'] for doc in documents]
        metadata = [doc.get('metadata', {}) for doc in documents]
        
        # Metinleri chunk'lara böl
        all_chunks = []
        all_metadata = []
        
        for text, meta in zip(texts, metadata):
            chunks = self.embedding_service.chunk_text(text)
            all_chunks.extend(chunks)
            # Her chunk için metadata'yı kopyala
            all_metadata.extend([meta] * len(chunks))
        
        # Tüm chunk'lar için embedding'leri al
        embeddings = []
        for chunk in all_chunks:
            embedding = await self.embedding_service.get_embedding(chunk)
            embeddings.append(embedding)
        
        # Vector store'a kaydet
        await self.vector_store.add_embeddings(all_chunks, embeddings, all_metadata)
    
    async def query(self, question: str, k: int = 3) -> List[Dict[str, Any]]:
        """
        Soru için en alakalı dökümanları bul
        
        Args:
            question: Sorgu metni
            k: Kaç sonuç döndürüleceği
            
        Returns:
            List[Dict]: Her biri {'text': str, 'distance': float, 'metadata': dict} formatında sonuçlar
        """
        # Soru için embedding al
        query_embedding = await self.embedding_service.get_embedding(question)
        
        # En yakın dökümanları bul
        results = await self.vector_store.search(query_embedding, k=k)
        return results 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\rag\simple_rag.py ====
from .base_rag import BaseRAG
from typing import List, Dict, Any
import asyncio

class SimpleRAG(BaseRAG):
    """Test için basit bir RAG implementasyonu"""
    
    def __init__(self, name: str, documents: Dict[str, str]):
        """
        Args:
            name: RAG sistemi adı
            documents: Anahtar-değer çiftleri olarak dökümanlar
        """
        self.name = name
        self.documents = documents

    async def add_documents(self, documents: List[Dict[str, Any]]) -> None:
        """Yeni dökümanlar ekle"""
        for doc in documents:
            self.documents[doc["id"]] = doc["content"]

    async def query(self, question: str) -> Dict[str, Any]:
        """Basit keyword matching ile ilgili dökümanları bul"""
        # Simüle edilmiş gecikme
        await asyncio.sleep(0.1)
        
        matching_docs = []
        for doc_id, content in self.documents.items():
            # Basit keyword matching
            if any(word.lower() in content.lower() for word in question.split()):
                matching_docs.append(f"[Doc {doc_id}]: {content}")

        context = "\n".join(matching_docs) if matching_docs else "No relevant documents found."
        
        return {
            "context": context,
            "metadata": {
                "source": self.name,
                "matched_docs": len(matching_docs)
            }
        }

    async def update_index(self) -> None:
        """Bu basit implementasyonda index güncellemeye gerek yok"""
        pass 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\rag\vector_store.py ====
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional
import numpy as np
from pgvector.asyncpg import register_vector
from sqlalchemy import create_engine
from sqlalchemy.ext.asyncio import create_async_engine
from config.settings import settings

class BaseVectorStore(ABC):
    """Vector store için temel sınıf"""
    
    @abstractmethod
    async def add_embeddings(self, texts: List[str], embeddings: List[List[float]], metadata: Optional[List[Dict]] = None):
        """Embedding'leri vector store'a ekle"""
        pass
    
    @abstractmethod
    async def search(self, query_embedding: List[float], k: int = 5) -> List[Dict[str, Any]]:
        """En yakın k dökümanı bul"""
        pass

class PGVectorStore(BaseVectorStore):
    """PostgreSQL pgvector extension kullanan vector store"""
    
    def __init__(self):
        self.engine = create_async_engine(settings.DATABASE_URL)
        
    async def init_db(self):
        """pgvector extension'ı yükle ve tabloyu oluştur"""
        async with self.engine.begin() as conn:
            await conn.execute('CREATE EXTENSION IF NOT EXISTS vector')
            await conn.execute('''
                CREATE TABLE IF NOT EXISTS document_embeddings (
                    id SERIAL PRIMARY KEY,
                    text TEXT NOT NULL,
                    embedding vector(1536) NOT NULL,
                    metadata JSONB
                )
            ''')
            await register_vector(conn)
    
    async def add_embeddings(self, texts: List[str], embeddings: List[List[float]], metadata: Optional[List[Dict]] = None):
        if metadata is None:
            metadata = [{}] * len(texts)
            
        async with self.engine.begin() as conn:
            for text, embedding, meta in zip(texts, embeddings, metadata):
                await conn.execute(
                    '''
                    INSERT INTO document_embeddings (text, embedding, metadata)
                    VALUES ($1, $2, $3)
                    ''',
                    text, embedding, meta
                )
    
    async def search(self, query_embedding: List[float], k: int = 5) -> List[Dict[str, Any]]:
        async with self.engine.begin() as conn:
            results = await conn.fetch(
                '''
                SELECT text, embedding <-> $1 as distance, metadata
                FROM document_embeddings
                ORDER BY distance ASC
                LIMIT $2
                ''',
                query_embedding, k
            )
            
            return [
                {
                    'text': row['text'],
                    'distance': float(row['distance']),
                    'metadata': row['metadata']
                }
                for row in results
            ]

# Factory pattern for vector store creation
def get_vector_store() -> BaseVectorStore:
    if settings.VECTOR_STORE_TYPE == "pgvector":
        return PGVectorStore()
    else:
        raise ValueError(f"Unsupported vector store type: {settings.VECTOR_STORE_TYPE}") 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\rag\__init__.py ====


==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\schemas\enums.py ====
from enum import Enum

class ProcessingStatus(str, Enum):
    pending = "pending"
    processing = "processing"
    completed = "completed"
    failed = "failed"

class FileType(str, Enum):
    pdf = "pdf"
    docx = "docx"
    txt = "txt"
    md = "md"
    unknown = "unknown" 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\services\base_model.py ====
# Path: chatbot_framework/core/services/base_model.py

from abc import ABC, abstractmethod
from typing import Dict, List, Optional, AsyncGenerator, Union

class BaseLanguageModel(ABC):
    """Tüm dil modelleri için temel arayüz"""
    
    @abstractmethod
    async def generate(self, 
                      prompt: str, 
                      messages: Optional[List[Dict[str, str]]] = None,
                      **kwargs) -> str:
        """Tek seferlik yanıt üretme"""
        pass

    @abstractmethod
    async def stream_generate(self,
                            prompt: str,
                            messages: Optional[List[Dict[str, str]]] = None,
                            **kwargs) -> AsyncGenerator[str, None]:
        """Stream şeklinde yanıt üretme"""
        pass

    @abstractmethod
    async def get_embeddings(self, texts: List[str]) -> List[List[float]]:
        """Metin embedding'leri için temel metod"""
        pass 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\services\document_processing.py ====
from core.database.models import RAGDocument
from core.schemas.enums import ProcessingStatus
from langchain_community.document_loaders import UnstructuredFileLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.schema import Document
import uuid
from pathlib import Path
import pickle
from sqlalchemy import select
from typing import List
from fastapi import HTTPException
from config.logger import app_logger
from core.services.file_upload import FileUploadService
from core.database.session import AsyncSessionLocal
from core.schemas.enums import FileType
import chardet
import hashlib
from unstructured.partition.auto import partition
from unstructured.partition.pdf import partition_pdf
from pi_heif import register_heif_opener
import os
import asyncio
from datetime import datetime
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text


# PDF/DOCX Processing
from pypdf import PdfReader
from docx import Document as DocxDocument

# Chunking - DÜZELTİLMİŞ IMPORT
from langchain_experimental.text_splitter import SemanticChunker, BreakpointThresholdType

class DocumentProcessor:
    def __init__(self):
        self.embedding_model = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
        )
        self.processed_dir = Path("processed_documents")
        self.processed_dir.mkdir(exist_ok=True)

    async def process_document(
        self,
        file_path: str,
        text_content: str,
        user_id: str,
        chunk_size: int = 1000,
        chunk_overlap: int = 200,
        max_file_size: int = 50 * 1024 * 1024
    ) -> List[RAGDocument]:
        """
        Güncellenmiş belge işleme akışı:
        1. Doğrudan gelen içeriği kullan
        2. Semantik chunking
        3. Veritabanına kayıt
        """
        try:
            # 1. Gelen içeriği temizle
            #cleaned_content = self._clean_text(text_content)
            
            # 2. Semantik Chunking
            chunks = await self._semantic_chunking(
                text_content,
                chunk_size,
                chunk_overlap
            )
            
            # 3. Veritabanına Toplu Kayıt
            return await self._bulk_insert_chunks(
                file_path=file_path,
                user_id=user_id,
                chunks=chunks,
                original_content=text_content
            )
            
        except Exception as e:
            app_logger.error(f"Belge işleme hatası: {str(e)}")
            raise HTTPException(500, "Belge işlenemedi")

    def _validate_file(self, file_path: str, max_size: int):
        """Dosya validasyonu"""
        # Tip kontrolü ekleyelim
        if not isinstance(file_path, (str, bytes, os.PathLike)):
            raise TypeError(f"Geçersiz dosya yolu tipi: {type(file_path)}")
        
        if not os.path.exists(file_path):
            raise HTTPException(404, "Dosya bulunamadı")
            
        if os.path.getsize(file_path) > max_size:
            raise HTTPException(413, "Dosya boyutu limiti aşıldı (50MB)")

    async def _extract_text(self, file_path: str) -> str:
        """Dosya türüne göre metin çıkarımı"""
        file_ext = os.path.splitext(file_path)[1].lower()
        
        try:
            if file_ext == ".pdf":
                text = await self._read_pdf(file_path)
            elif file_ext == ".docx":
                text = await self._read_docx(file_path)
            else:
                raise HTTPException(400, "Desteklenmeyen dosya formatı")
            
            
            # Metni temizleme
            return self._clean_text(text)

        except Exception as e:
            app_logger.error(f"Metin çıkarım hatası: {str(e)}")
            raise HTTPException(500, "Dosya içeriği okunamadı")


    # PDF'den metin çıkarımı

    async def _read_pdf(self, file_path: str) -> str:
        """PDF'den metin çıkarımı (Unstructured ile, OCR devre dışı)"""
        from unstructured.partition.pdf import partition_pdf

        elements = partition_pdf(
            filename=file_path,
            strategy="hi_res",         # "auto" yerine "hi_res" veya "fast" vb. kullanılabilir
            infer_table_structure=True,
            languages=["tur", "eng"],
            ocr_strategy="none"        # <-- OCR kapalı
        )
        return "\n\n".join([str(e) for e in elements])


    async def _read_pdf(self, file_path: str) -> str:
        """PDF'den metin çıkarımı (Unstructured ile)"""
        elements = partition_pdf(
            filename=file_path,
            strategy="auto",
            infer_table_structure=True,
            languages=["tur", "eng"]
        )
        return "\n\n".join([str(e) for e in elements])

    async def _read_docx(self, file_path: str) -> str:
        """DOCX'ten metin çıkarımı"""
        def sync_read():
            doc = DocxDocument(file_path)
            return "\n".join([p.text for p in doc.paragraphs])
            
        return await asyncio.to_thread(sync_read)

    async def _semantic_chunking(
        self,
        text: str,
        chunk_size: int,
        chunk_overlap: int
    ) -> List[str]:
        """Advanced semantic chunking with multiple threshold strategies"""
        chunker = SemanticChunker(
            embeddings=self.embedding_model,
            breakpoint_threshold_type=BreakpointThresholdType.PERCENTILE,  # Default strategy
            breakpoint_threshold_amount=85,  # 85th percentile cutoff
            min_chunk_size=100  # Minimum characters per chunk
        )
        
        return await asyncio.to_thread(
            chunker.split_text,
            text=text,
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap
        )

    # Optional alternative strategies
    def _create_standard_deviation_chunker(self):
        return SemanticChunker(
            embeddings=self.embedding_model,
            breakpoint_threshold_type=BreakpointThresholdType.STANDARD_DEVIATION,
            breakpoint_threshold_amount=2.5  # 2.5 standard deviations
        )

    def _create_interquartile_chunker(self):
        return SemanticChunker(
            embeddings=self.embedding_model,
            breakpoint_threshold_type=BreakpointThresholdType.INTERQUARTILE,
            breakpoint_threshold_amount=1.8  # 1.8 * IQR
        )

    def _create_gradient_chunker(self):
        return SemanticChunker(
            embeddings=self.embedding_model,
            breakpoint_threshold_type="gradient",  # Experimental gradient method
            breakpoint_threshold_amount=90  # 90th percentile on gradient
        )

    async def _bulk_insert_chunks(
        self,
        file_path: str,
        user_id: str,
        chunks: List[str],
        original_content: str
    ) -> List[RAGDocument]:
        """Toplu veri ekleme ile performans optimizasyonu"""
        file_checksum = hashlib.sha256(original_content.encode()).hexdigest()
        file_size = os.path.getsize(file_path)
        file_type = os.path.splitext(file_path)[1][1:].upper()
        created_at = datetime.utcnow()

        # RAGDocument nesnelerini oluştur
        documents = [
            RAGDocument(
                title=f"{os.path.basename(file_path)} - Chunk {i}",
                content=self._clean_text(chunk),
                user_id=user_id,
                file_path=file_path,
                file_type=file_type,
                file_size=file_size,
                file_checksum=file_checksum,
                processing_status=ProcessingStatus.PROCESSED,
                chunk_size=len(chunk),
                chunk_index=i,
                created_at=created_at,
                updated_at=created_at,
                metadata={
                    "chunking_method": "semantic_v2",
                    "language": "turkish",
                    "checksum": hashlib.sha256(chunk.encode()).hexdigest()
                }
            )
            for i, chunk in enumerate(chunks)
        ]

        # Toplu veritabanı işlemi
        async with AsyncSessionLocal() as session:
            try:
                session.add_all(documents)
                await session.commit()
                return documents
            except Exception as e:
                await session.rollback()
                app_logger.error(f"Veritabanı kayıt hatası: {str(e)}")
                raise HTTPException(500, "Veritabanı işlemi başarısız")

    def _detect_file_type(self, filename: str) -> str:
        ext = filename.split(".")[-1].lower()
        if ext in ["pdf", "docx", "txt", "md"]:
            return ext
        raise ValueError("Desteklenmeyen dosya formatı")

    def _move_to_processed(self, temp_path: str, doc_id: str) -> Path:
        final_path = self.processed_dir / f"{doc_id}.pdf"
        Path(temp_path).rename(final_path)
        return final_path 

    async def get_user_documents(self, user_id: str):
        result = await self.db.execute(
            select(RAGDocument)
            .filter(RAGDocument.user_id == user_id)
            .order_by(RAGDocument.created_at.desc())
        )
        return result.scalars().all()

    async def _store_embeddings(self, doc: RAGDocument, chunks: List[Document]):
        try:
            from core.rag.vector_store import get_vector_store
            vector_store = get_vector_store()
            
            texts = [chunk.page_content for chunk in chunks]
            embeddings = self.embedding_model.embed_documents(texts)
            
            await vector_store.bulk_insert(
                texts=texts,
                embeddings=embeddings,
                metadatas=[{
                    "doc_id": doc.id,
                    "source": doc.title,
                    "page": idx
                } for idx in range(len(chunks))]
            )
            
            doc.processing_status = "processed"
            await self.db.commit()
        except Exception as e:
            doc.processing_status = "failed"
            doc.processing_errors = str(e)
            await self.db.commit()
            raise 

    async def _save_embeddings(self, chunks: List[Document]):
        try:
            # Numpy array'i bytes'a çevirme
            embeddings = self.embedding_model.embed_documents([chunk.page_content for chunk in chunks])
            return [emb.tobytes() for emb in embeddings]  # Numpy array -> bytes
        except Exception as e:
            app_logger.error(f"Embedding hatası: {str(e)}")
            raise 

    async def read_file_content(self, content: bytes, file_extension: str) -> str:
        """Dosya içeriğini doğru encoding ile okur"""
        try:
            # 1. Encoding tespiti
            detected = chardet.detect(content)
            encoding = detected['encoding'] or 'utf-8'
            
            # 2. Türkçe karakterler için özel handling
            try:
                return content.decode(encoding)
            except UnicodeDecodeError:
                return content.decode('iso-8859-1')  # Fallback encoding
            except LookupError:
                return content.decode('utf-8', errors='replace')
            
        except Exception as e:
            app_logger.warning(f"Dosya içeriği okunamadı ({file_extension}): {str(e)}")
            return "" 


    def _clean_text(self, text: str) -> str:
        """Metni temizleme ve normalleştirme"""
        return text.replace('\x00', '').replace('\ufeff', '').strip()

    async def _adaptive_chunking(self, text: str) -> List[str]:
        """Bağlama duyarlı chunklama"""
       # from semantic_chunking import SemanticChunker
        chunker = SemanticChunker(
            breakpoint_threshold_type="percentile",
            breakpoint_threshold_amount=85
        )
        return chunker.split_text(text)

    async def _batch_embedding(self, chunks: List[str]) -> List[List[float]]:
        """Toplu embedding işlemi"""
        from sentence_transformers import SentenceTransformer
        model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')
        return model.encode(chunks).tolist()

    def _generate_semantic_hash(self, text: str) -> str:
        """Metin için anlamsal hash üretimi"""
        return hashlib.sha256(text.encode('utf-8')).hexdigest()[:16] 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\services\file_upload.py ====
import hashlib
from fastapi import UploadFile, HTTPException
from pathlib import Path
import uuid
from typing import Optional
from config.logger import app_logger
from core.schemas.enums import FileType
from PyPDF2 import PdfReader
from docx import Document
import io

class FileUploadService:
    def __init__(self):
        self.temp_dir = Path("temp")
        self.temp_dir.mkdir(exist_ok=True)
        
        self.processed_dir = Path("processed_documents")
        self.processed_dir.mkdir(exist_ok=True)

    async def read_file_content(self, content: bytes, file_extension: str) -> str:
        """Dosya içeriğini okur ve metin olarak döndürür."""
        try:
            if file_extension == '.pdf':
                pdf = PdfReader(io.BytesIO(content))
                return "\n".join(page.extract_text() for page in pdf.pages)
                
            elif file_extension == '.docx':
                doc = Document(io.BytesIO(content))
                return "\n".join(paragraph.text for paragraph in doc.paragraphs)
                
            elif file_extension in ['.txt', '.md']:
                return content.decode('utf-8')
                
            return ""  # Desteklenmeyen dosya tipi için boş string
            
        except Exception as e:
            app_logger.error(f"Dosya içeriği okuma hatası: {str(e)}")
            return ""

    async def save_temp_file(self, file: UploadFile, current_user=None) -> dict:
        try:
            # 1. Dosya validasyonu
            if not file.filename:
                raise HTTPException(400, "Geçersiz dosya adı")
                
            file_extension = Path(file.filename).suffix.lower()
            allowed_extensions = {'.pdf', '.docx', '.txt', '.md'}
            if file_extension not in allowed_extensions:
                raise HTTPException(400, "Desteklenmeyen dosya formatı")

            # 2. Dosya boyutu kontrolü (max 20MB)
            max_size = 20 * 1024 * 1024  # 20MB
            content = await file.read()
            if len(content) > max_size:
                raise HTTPException(413, "Dosya boyutu 20MB'ı aşıyor")

            # 3. Checksum hesapla ve tekrarı kontrol et
            checksum = hashlib.sha256(content).hexdigest()
            existing = await self.check_existing_file(checksum)
            if existing:
                return existing

            # 4. Dosya içeriğini oku
            file_content_str = await self.read_file_content(content, file_extension)
            if not file_content_str:
                app_logger.warning(f"Boş içerik: {file.filename}")
                file_content_str = ""  # NULL yerine boş string

            # 5. Geçici dosyayı kaydet
            file_id = f"{uuid.uuid4()}{file_extension}"
            temp_path = self.temp_dir / file_id
            
            with open(temp_path, "wb") as f:
                f.write(content)
                
            # Dosya tipini belirleme
            file_type_map = {
                '.pdf': FileType.pdf,
                '.docx': FileType.docx,
                '.txt': FileType.txt,
                '.md': FileType.md
            }
            file_type = file_type_map.get(file_extension, FileType.unknown)
            
            return {
                "file_id": file_id,
                "original_name": file.filename,
                "size": len(content),
                "checksum": checksum,
                "temp_path": str(temp_path),
                "content_type": file.content_type,
                "file_type": file_type,
                "content": file_content_str  # Mutlaka string gönder
            }
            
        except HTTPException as he:
            app_logger.error(
                "Dosya yükleme hatası (Kullanıcı: %s): %s", 
                current_user.id if current_user else "anon", 
                str(he.detail)
            )
            raise he
        except Exception as e:
            app_logger.exception("Beklenmeyen yükleme hatası")
            raise HTTPException(500, "Dosya işlenemedi")

    async def move_to_processed(self, temp_path: str) -> str:
        processed_path = self.processed_dir / Path(temp_path).name
        Path(temp_path).rename(processed_path)
        return str(processed_path)

    async def check_existing_file(self, checksum: str) -> Optional[dict]:
        # Veritabanında checksum kontrolü yap
        # Örnek implementasyon:
        # from core.database import get_db
        # async with get_db() as db:
        #     existing = await db.execute(select(RAGDocument).filter_by(file_checksum=checksum))
        #     if existing: return existing.first()
        return None 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\services\ollama_service.py ====
# Path: chatbot_framework/core/services/ollama_service.py

from .base_model import BaseLanguageModel
import httpx
from typing import List, Optional, AsyncGenerator, Union, AsyncIterator
import json
import os
import aiohttp

class OllamaService(BaseLanguageModel):
    def __init__(self, model: str = "llama2"):
        self.base_url = "http://localhost:11434"
        self.model = model
        self.timeout = 30
        self.client = httpx.AsyncClient(timeout=self.timeout)

    async def generate(self, 
                      prompt: str, 
                      system_message: Optional[str] = None,
                      **kwargs) -> str:
        try:
            if system_message:
                prompt = f"{system_message}\n\n{prompt}"
            
            response = await self.client.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    **kwargs
                }
            )
            
            if response.status_code != 200:
                raise Exception(f"Ollama API error: {response.text}")
                
            return response.json()["response"]

        except Exception as e:
            print(f"Ollama Generate Error: {str(e)}")
            raise

    async def stream_generate(self,
                            prompt: str,
                            system_message: Optional[str] = None,
                            **kwargs) -> AsyncGenerator[str, None]:
        try:
            if system_message:
                prompt = f"{system_message}\n\n{prompt}"
                
            async with self.client.stream(
                "POST",
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": True,
                    **kwargs
                }
            ) as response:
                async for line in response.aiter_lines():
                    if line:
                        data = json.loads(line)
                        if "response" in data:
                            yield data["response"]
                            
        except Exception as e:
            print(f"Ollama Streaming Error: {str(e)}")
            raise

    async def get_embeddings(self, texts: List[str]) -> List[List[float]]:
        try:
            embeddings = []
            for text in texts:
                response = await self.client.post(
                    f"{self.base_url}/api/embeddings",
                    json={
                        "model": self.model,
                        "prompt": text
                    }
                )
                
                if response.status_code != 200:
                    raise Exception(f"Ollama API error: {response.text}")
                    
                response_data = response.json()
                embeddings.append(response_data.get("embedding", []))
            return embeddings
        except Exception as e:
            print(f"Ollama Embeddings Error: {str(e)}")
            raise

    async def __aenter__(self):
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.client.aclose()

    async def chat_stream(self, prompt: str, system_message: str = None) -> AsyncGenerator[str, None]:
        messages = []
        if system_message:
            messages.append({"role": "system", "content": system_message})
        messages.append({"role": "user", "content": prompt})

        async with aiohttp.ClientSession() as session:
            try:
                async with session.post(
                    f"{self.base_url}/api/chat",
                    json={
                        "model": self.model,
                        "messages": messages,
                        "stream": True
                    }
                ) as response:
                    if response.status != 200:
                        error = await response.text()
                        raise Exception(f"Ollama API error: {error}")

                    async for line in response.content:
                        if line:
                            chunk = json.loads(line)
                            if "message" in chunk and "content" in chunk["message"]:
                                yield chunk["message"]["content"]
                                
            except Exception as e:
                print(f"Ollama stream error: {str(e)}")
                yield f"Error: {str(e)}"

    async def chat(self, message: str, system_message: Optional[str] = None) -> str:
        try:
            prompt = message
            if system_message:
                prompt = f"{system_message}\n\nUser: {message}\nAssistant:"

            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.base_url}/api/generate",
                    json={
                        "model": self.model,
                        "prompt": prompt
                    }
                )
                data = response.json()
                return data.get("response", "")

        except Exception as e:
            print(f"Ollama chat error: {str(e)}")
            return f"Error: {str(e)}"

    async def list_models(self) -> List[str]:
        """Ollama modellerini listeler."""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(f'{self.base_url}/v1/models')
                if response.status_code == 200:
                    data = response.json()
                    if isinstance(data, dict) and "data" in data:
                        return sorted([
                            model["id"].split(':')[0]
                            for model in data["data"]
                        ])
        except Exception as e:
            print(f"Ollama API error: {str(e)}")
            return []
        return []


==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\services\openai_service.py ====
# Path: chatbot_framework/core/services/openai_service.py

from typing import AsyncIterator, Optional, List
from openai import AsyncOpenAI
import os

class OpenAIService:
    def __init__(self, api_key: Optional[str] = None, model: str = "gpt-3.5-turbo"):
        self.client = AsyncOpenAI(api_key=api_key or os.getenv("OPENAI_API_KEY"))
        self.model = model

    async def list_models(self) -> List[str]:
        """OpenAI modellerini listeler."""
        try:
            response = await self.client.models.list()
            return sorted([
                model.id for model in response.data 
                if any(x in model.id.lower() for x in ["gpt-3.5", "gpt-4"])
            ])
        except Exception as e:
            print(f"OpenAI API error: {str(e)}")
            return []

    async def chat_stream(self, message: str, system_message: Optional[str] = None) -> AsyncIterator[str]:
        messages = []
        if system_message:
            messages.append({"role": "system", "content": system_message})
        messages.append({"role": "user", "content": message})

        try:
            stream = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                stream=True
            )
            
            async for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    yield chunk.choices[0].delta.content

        except Exception as e:
            print(f"OpenAI stream error: {str(e)}")
            yield f"Error: {str(e)}"

    async def chat(self, message: str, system_message: Optional[str] = None) -> str:
        messages = []
        if system_message:
            messages.append({"role": "system", "content": system_message})
        messages.append({"role": "user", "content": message})

        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"OpenAI chat error: {str(e)}")
            return f"Error: {str(e)}"


==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\core\services\__init__.py ====


==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\frontend\app.js ====
class ChatApp {
    constructor() {
        this.apiUrl = 'http://localhost:8000';
        this.token = localStorage.getItem('token');
        this.currentConversationId = null;  // Mevcut sohbet oturumunun ID'sini tutar

        // DOM elementleri
        this.authContainer = document.getElementById('auth-container');
        this.mainContainer = document.getElementById('main-container');
        this.messageInput = document.getElementById('message-input');
        this.chatMessages = document.getElementById('chat-messages');
        this.assistantSelect = document.getElementById('assistant-select');
        this.sendButton = document.getElementById('send-button');
        this.currentAssistantHeader = document.getElementById('current-assistant');

        // Token kontrolü
        if (!this.token) {
            this.showAuthContainer();
        } else {
            this.showMainContainer();
            this.initializeApp();
        }

        // Auth event listeners
        this.setupAuthEventListeners();

        // Load Conversations butonu için event listener
        const loadConversationsBtn = document.getElementById('load-conversations');
        if (loadConversationsBtn) {
            loadConversationsBtn.addEventListener('click', () => this.loadConversations());
        }

        // Logout butonu için event listener
        const logoutBtn = document.getElementById('logout-button');
        if (logoutBtn) {
            logoutBtn.addEventListener('click', () => this.handleLogout());
        }

        // Model parametreleri için event listener'lar
        ['temperature', 'top-p', 'max-tokens', 'frequency-penalty', 'presence-penalty'].forEach(param => {
            const slider = document.getElementById(param);
            const value = document.getElementById(`${param}-value`);
            if (slider && value) {
                slider.addEventListener('input', (e) => {
                    value.textContent = e.target.value;
                });
            }
        });

        // Model seçimi değiştiğinde
        const modelType = document.getElementById('model-type');
        if (modelType) {
            modelType.addEventListener('change', () => this.loadModels(modelType.value));
        }

        // Create Assistant butonu için event listener
        const createAssistantBtn = document.getElementById('create-assistant-btn');
        if (createAssistantBtn) {
            createAssistantBtn.addEventListener('click', () => this.createAssistant());
        }

        // Yeni Sohbet butonu
        const newChatButton = document.getElementById('new-chat-button');
        if (newChatButton) {
            newChatButton.addEventListener('click', () => this.startNewConversation());
        }

        this.initFileUpload();
    }

    initializeApp() {
        // Asistanları yükle
        this.loadAssistants();

        // Event listeners
        if (this.assistantSelect) {
            this.assistantSelect.addEventListener('change', (e) => {
                this.currentAssistant = e.target.value;
                if (this.currentAssistant && this.currentAssistantHeader) {
                    this.currentAssistantHeader.textContent = `Chat with ${this.currentAssistant}`;
                }
            });
        }

        if (this.sendButton) {
            this.sendButton.addEventListener('click', () => this.sendMessage());
        }

        if (this.messageInput) {
            this.messageInput.addEventListener('keypress', (e) => {
                if (e.key === 'Enter') this.sendMessage();
            });
        }
    }

    async loadAssistants() {
        try {
            const response = await fetch(`${this.apiUrl}/assistants/list`, {
                headers: {
                    'Authorization': `Bearer ${this.token}`
                }
            });

            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`);
            }

            const assistants = await response.json();

            // Asistan listesini güncelle
            if (this.assistantSelect) {
                this.assistantSelect.innerHTML = '<option value="">Choose an assistant...</option>';
                assistants.forEach(assistant => {
                    const option = document.createElement('option');
                    option.value = assistant.name;
                    option.textContent = assistant.name;
                    this.assistantSelect.appendChild(option);
                });
            }
        } catch (error) {
            console.error('Error loading assistants:', error);
            this.showError('Failed to load assistants: ' + error.message);
        }
    }

    addMessage(text, isUser = false) {
        const messageDiv = document.createElement('div');
        messageDiv.className = `message ${isUser ? 'user' : 'assistant'}`;
        messageDiv.textContent = text;
        this.chatMessages.appendChild(messageDiv);
        this.chatMessages.scrollTop = this.chatMessages.scrollHeight;
    }

    async sendMessage() {
        const message = this.messageInput.value.trim();
        if (!message || !this.currentAssistant) {
            this.showError('Lütfen bir asistan seçin ve mesaj girin');
            return;
        }

        try {
            // Mesajı göster
            this.addMessage(message, true);
            this.messageInput.value = '';

            // URL oluştur
            const url = new URL(`${this.apiUrl}/assistants/${encodeURIComponent(this.currentAssistant)}/chat/stream`);
            url.searchParams.append('message', message);
            
            if (this.currentConversationId) {
                url.searchParams.append('conversation_id', this.currentConversationId);
            }

            // Fetch isteği
            const response = await fetch(url, {
                headers: {
                    'Authorization': `Bearer ${this.token}`,
                    'Accept': 'text/event-stream'
                }
            });

            if (!response.ok) {
                const errorText = await response.text();
                throw new Error(`HTTP ${response.status}: ${errorText}`);
            }

            // Conversation ID'yi header'dan al
            const newConversationId = response.headers.get('X-Conversation-Id');
            if (newConversationId && !this.currentConversationId) {
                this.currentConversationId = newConversationId;
                console.log('Yeni konuşma ID:', this.currentConversationId);
            }

            // Asistan yanıtı için yeni bir mesaj oluştur
            const assistantMessage = document.createElement('div');
            assistantMessage.className = 'message assistant';
            this.chatMessages.appendChild(assistantMessage);

            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            let buffer = '';

            try {
                while (true) {
                    const { done, value } = await reader.read();
                    if (done) break;

                    buffer += decoder.decode(value, { stream: true });
                    let lines = buffer.split('\n');
                    buffer = lines.pop() || '';

                    for (const line of lines) {
                        const trimmedLine = line.trim();
                        if (trimmedLine.startsWith('data: ')) {
                            const token = trimmedLine.slice(6);
                            if (token && token !== '[DONE]') {
                                if (token.startsWith('error:')) {
                                    throw new Error(token.slice(6));
                                }
                                assistantMessage.textContent += token;
                                this.chatMessages.scrollTop = this.chatMessages.scrollHeight;
                            }
                        }
                    }
                }
            } catch (streamError) {
                console.error('Stream error:', streamError);
                throw streamError;
            } finally {
                // Reader'ı sonlandır
                reader.cancel();
            }

        } catch (error) {
            console.error('Mesaj gönderme hatası:', error);
            this.showError(`Hata: ${error.message}`);
            this.addMessage('Üzgünüm, bir hata oluştu. Lütfen tekrar deneyin.', false);
        }
    }

    showError(message) {
        const alertContainer = document.getElementById('alert-container') || document.body;
        const alertDiv = document.createElement('div');
        alertDiv.className = 'alert alert-danger alert-dismissible fade show position-fixed top-0 start-50 translate-middle-x mt-3';
        alertDiv.style.zIndex = '9999';
        alertDiv.innerHTML = `
            ${message}
            <button type="button" class="btn-close" data-bs-dismiss="alert" aria-label="Close"></button>
        `;
        alertContainer.appendChild(alertDiv);

        setTimeout(() => {
            alertDiv.remove();
        }, 5000);
    }

    showSuccess(message) {
        const alertContainer = document.getElementById('alert-container') || document.body;
        const alertDiv = document.createElement('div');
        alertDiv.className = 'alert alert-success alert-dismissible fade show position-fixed top-0 start-50 translate-middle-x mt-3';
        alertDiv.style.zIndex = '9999';
        alertDiv.innerHTML = `
            ${message}
            <button type="button" class="btn-close" data-bs-dismiss="alert" aria-label="Close"></button>
        `;
        alertContainer.appendChild(alertDiv);

        setTimeout(() => {
            alertDiv.remove();
        }, 5000);
    }

    // ===================== AUTH METHODS =====================
    async handleLogin(event) {
        event.preventDefault();
        const email = document.getElementById('login-email').value;
        const password = document.getElementById('login-password').value;

        try {
            const formData = new URLSearchParams();
            formData.append('username', email);
            formData.append('password', password);

            const response = await fetch(`${this.apiUrl}/auth/token`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/x-www-form-urlencoded'
                },
                body: formData
            });

            const data = await response.json();

            if (!response.ok) {
                throw new Error(data.detail || 'Login failed');
            }

            // Token'ı sakla
            this.token = data.access_token;
            localStorage.setItem('token', this.token);

            // Ana uygulamayı başlat
            this.showMainContainer();
            this.initializeApp();

        } catch (error) {
            console.error('Login error:', error);
            this.showError('Error: ' + error.message);
        }
    }

    async handleRegister(event) {
        event.preventDefault();
        const email = document.getElementById('register-email').value;
        const username = document.getElementById('register-username').value;
        const password = document.getElementById('register-password').value;

        try {
            const response = await fetch(`${this.apiUrl}/auth/register`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({ email, username, password })
            });

            const data = await response.json();

            if (!response.ok) {
                throw new Error(data.detail || 'Registration failed');
            }

            // Başarılı kayıt mesajı göster
            this.showSuccess('Registration successful! Please login.');
            // Login formunu göster
            this.toggleAuthForms('login');

        } catch (error) {
            console.error('Registration error:', error);
            this.showError(error.message);
        }
    }

    toggleAuthForms(show = 'login') {
        const loginForm = document.getElementById('login-form');
        const registerForm = document.getElementById('register-form');

        if (!loginForm || !registerForm) {
            console.error('Auth forms not found in DOM');
            return;
        }

        if (show === 'login') {
            loginForm.style.display = 'block';
            registerForm.style.display = 'none';
        } else {
            loginForm.style.display = 'none';
            registerForm.style.display = 'block';
        }
    }

    showAuthContainer() {
        if (this.authContainer) {
            this.authContainer.style.display = 'block';
            this.toggleAuthForms('login');
        }
        if (this.mainContainer) {
            this.mainContainer.style.display = 'none';
        }
    }

    showMainContainer() {
        if (this.authContainer) {
            this.authContainer.style.display = 'none';
        }
        if (this.mainContainer) {
            this.mainContainer.style.display = 'block';
        }
    }

    setupAuthEventListeners() {
        const loginForm = document.getElementById('login-form-element');
        const registerForm = document.getElementById('register-form-element');
        const showRegisterBtn = document.getElementById('show-register');
        const showLoginBtn = document.getElementById('show-login');

        if (loginForm) {
            loginForm.addEventListener('submit', (e) => this.handleLogin(e));
        }
        if (registerForm) {
            registerForm.addEventListener('submit', (e) => this.handleRegister(e));
        }
        if (showRegisterBtn) {
            showRegisterBtn.addEventListener('click', () => this.toggleAuthForms('register'));
        }
        if (showLoginBtn) {
            showLoginBtn.addEventListener('click', () => this.toggleAuthForms('login'));
        }
    }
    // ========================================================

    async loadConversations() {
        try {
            const response = await fetch(`${this.apiUrl}/assistants/conversations`, {
                headers: {
                    'Authorization': `Bearer ${this.token}`
                }
            });

            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`);
            }

            const conversations = await response.json();
            const conversationList = document.getElementById('conversations-list');

            if (conversationList) {
                conversationList.innerHTML = ''; // Listeyi temizle

                conversations.forEach(conv => {
                    const item = document.createElement('div');
                    item.classList.add('conversation-item', 'p-2', 'border-bottom', 'hover-bg-light');

                    // Tarih formatını düzenle
                    const date = new Date(conv.created_at);
                    const formattedDate = date.toLocaleString('tr-TR', {
                        day: '2-digit',
                        month: '2-digit',
                        year: 'numeric',
                        hour: '2-digit',
                        minute: '2-digit'
                    });

                    item.innerHTML = `
                        <div class="d-flex justify-content-between align-items-center">
                            <div class="conversation-info">
                                <div class="fw-bold text-truncate" style="max-width: 150px;">
                                    ${conv.assistant_name}
                                </div>
                                <small class="text-muted">
                                    <i class="bi bi-clock"></i> ${formattedDate}
                                </small>
                            </div>
                            <button class="btn btn-sm btn-primary load-chat" 
                                    data-conversation-id="${conv.id}">
                                <i class="bi bi-chat-dots"></i> Load
                            </button>
                        </div>
                    `;

                    // Load Chat butonuna tıklama
                    const loadChatBtn = item.querySelector('.load-chat');
                    if (loadChatBtn) {
                        loadChatBtn.addEventListener('click', () => this.loadChat(conv.id));
                    }

                    conversationList.appendChild(item);
                });
            }
        } catch (error) {
            console.error('Failed to load conversations:', error);
            this.showError('Failed to load conversations: ' + error.message);
        }
    }

    async loadChat(conversationId) {
        try {
            const response = await fetch(`${this.apiUrl}/assistants/conversations/${conversationId}/messages`, {
                headers: {
                    'Authorization': `Bearer ${this.token}`
                }
            });

            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`);
            }

            const messages = await response.json();

            // Chat alanını temizle
            if (this.chatMessages) {
                this.chatMessages.innerHTML = '';
                // conversation_id'yi sakla
                this.currentConversationId = conversationId;
            }

            // Mesajları ekrana bas
            messages.forEach(msg => {
                const messageDiv = document.createElement('div');
                messageDiv.className = `message ${msg.role === 'user' ? 'user' : 'assistant'}`;
                messageDiv.textContent = msg.content;
                this.chatMessages.appendChild(messageDiv);
            });

            this.chatMessages.scrollTop = this.chatMessages.scrollHeight;

        } catch (error) {
            console.error('Failed to load chat:', error);
            this.showError('Failed to load chat: ' + error.message);
        }
    }

    async handleLogout() {
        try {
            const response = await fetch(`${this.apiUrl}/auth/logout`, {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${this.token}`
                }
            });

            if (!response.ok) {
                throw new Error('Logout failed');
            }

            // Token'ı sil ve login sayfasına yönlendir
            localStorage.removeItem('token');
            this.token = null;

            // UI güncelle
            this.authContainer.style.display = 'block';
            this.mainContainer.style.display = 'none';

            // Login formunu sıfırla
            document.getElementById('login-email').value = '';
            document.getElementById('login-password').value = '';

        } catch (error) {
            console.error('Logout error:', error);
            this.showError('Logout failed: ' + error.message);
        }
    }

    async loadModels(provider) {
        try {
            const response = await fetch(`${this.apiUrl}/assistants/models`, {
                headers: {
                    'Authorization': `Bearer ${this.token}`
                }
            });

            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`);
            }

            const models = await response.json();
            const modelSelect = document.getElementById('model-name');

            if (modelSelect) {
                modelSelect.innerHTML = '<option value="">Select a model...</option>';

                // Seçilen sağlayıcıya göre modeller
                if (models[provider]) {
                    models[provider].forEach(model => {
                        const option = document.createElement('option');
                        option.value = model;
                        option.textContent = model;
                        modelSelect.appendChild(option);
                    });
                }
            }
        } catch (error) {
            console.error('Failed to load models:', error);
            this.showError('Failed to load models: ' + error.message);
        }
    }

    async createAssistant() {
        try {
            const name = document.getElementById('assistant-name').value;
            const modelType = document.getElementById('model-type').value;
            const modelName = document.getElementById('model-name').value;
            const systemMessage = document.getElementById('system-message').value;

            if (!name || !modelType || !modelName || !systemMessage) {
                this.showError('Please fill in all required fields');
                return;
            }

            const config = {
                temperature: parseFloat(document.getElementById('temperature').value),
                top_p: parseFloat(document.getElementById('top-p').value),
                max_tokens: parseInt(document.getElementById('max-tokens').value),
                frequency_penalty: parseFloat(document.getElementById('frequency-penalty').value),
                presence_penalty: parseFloat(document.getElementById('presence-penalty').value)
            };

            const response = await fetch(`${this.apiUrl}/assistants/create`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${this.token}`
                },
                body: JSON.stringify({
                    name: name,
                    model_type: modelType,
                    model_name: modelName,
                    system_message: systemMessage,
                    config: config
                })
            });

            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`);
            }

            const result = await response.json();

            // Modal'ı kapat (Bootstrap 5)
            const modal = bootstrap.Modal.getInstance(document.getElementById('createAssistantModal'));
            if (modal) modal.hide();

            // Asistan listesini yenile
            await this.loadAssistants();

            // Başarı mesajı
            this.showSuccess('Assistant created successfully!');

        } catch (error) {
            console.error('Failed to create assistant:', error);
            this.showError('Failed to create assistant: ' + error.message);
        }
    }

    // ===================== Yeni sohbet başlatma =====================
    startNewConversation() {
        this.currentConversationId = null;
        this.clearChatMessages();

        // Başlık güncelle
        if (this.currentAssistant && this.currentAssistantHeader) {
            this.currentAssistantHeader.textContent = `New Chat with ${this.currentAssistant}`;
        }

        // Mesaj input alanını temizle
        if (this.messageInput) {
            this.messageInput.value = '';
        }

        console.log('Started new conversation');
    }

    clearChatMessages() {
        if (this.chatMessages) {
            this.chatMessages.innerHTML = '';
        }
    }

    initFileUpload() {
        const dropZone = document.querySelector('.file-drop-zone');
        if (!dropZone) return;

        // Drag & Drop event handlers
        dropZone.addEventListener('dragover', (e) => {
            e.preventDefault();
            dropZone.classList.add('drag-over');
        });

        dropZone.addEventListener('dragleave', () => {
            dropZone.classList.remove('drag-over');
        });

        dropZone.addEventListener('drop', async (e) => {
            e.preventDefault();
            dropZone.classList.remove('drag-over');
            const file = e.dataTransfer.files[0];
            if (file) await this.handleFileUpload(file);
        });

        // Click to upload
        dropZone.addEventListener('click', () => {
            const input = document.createElement('input');
            input.type = 'file';
            input.accept = '.pdf,.docx,.txt,.md';
            input.onchange = async (e) => {
                const file = e.target.files[0];
                if (file) await this.handleFileUpload(file);
            };
            input.click();
        });
    }

    async handleFileUpload(file) {
        // Dosya tipi kontrolü
        const validTypes = ['application/pdf', 
                          'text/plain',
                          'application/vnd.openxmlformats-officedocument.wordprocessingml.document'];
        
        if(!validTypes.includes(file.type)) {
            this.showError('Desteklenmeyen dosya formatı');
            return;
        }
        
        // Dosya boyutu kontrolü (20MB)
        if(file.size > 20 * 1024 * 1024) {
            this.showError('Dosya boyutu 20MB sınırını aşıyor');
            return;
        }
        
        // Yükleme işlemi
        try {
            const formData = new FormData();
            formData.append('file', file);
            
            const response = await fetch(`${this.apiUrl}/documents/upload`, {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${this.token}`
                },
                body: formData
            });
            
            if(!response.ok) throw new Error(await response.text());
            
            // Başarılı yanıt
            const result = await response.json();
            this.updateFileList(result);
            
        } catch(error) {
            console.error('Yükleme hatası:', error);
            this.showError(`Sunucu hatası: ${error.message}`);
        }
    }

    addFileToList(fileData) {
        const fileList = document.querySelector('.file-list');
        const fileItem = document.createElement('div');
        fileItem.className = 'file-item p-2 mb-2 border rounded';
        fileItem.innerHTML = `
            <div class="d-flex justify-content-between align-items-center">
                <div>
                    <i class="bi bi-file-text me-2"></i>
                    ${fileData.title} (${Math.round(fileData.file_size/1024)}KB)
                </div>
                <span class="badge bg-success">Yüklendi</span>
            </div>
        `;
        fileList.prepend(fileItem);
    }
}

// Global scope'a ekle
window.ChatApp = ChatApp;


==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\frontend\index.html ====
<!DOCTYPE html>
<html lang="tr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Çevre ve Şehircilik Bakanlığı AI Asistanı</title>
    
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <!-- Bootstrap Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.css">
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' width='16' height='16' fill='currentColor' class='bi bi-robot' viewBox='0 0 16 16'><path d='M6 12.5a.5.5 0 0 1 .5-.5h3a.5.5 0 0 1 0 1h-3a.5.5 0 0 1-.5-.5M3 8.062C3 6.76 4.235 5.765 5.53 5.886a26.6 26.6 0 0 0 4.94 0C11.765 5.765 13 6.76 13 8.062v1.157a.93.93 0 0 1-.765.935c-.845.147-2.34.346-4.235.346s-3.39-.2-4.235-.346A.93.93 0 0 1 3 9.219zm4.542-.827a.25.25 0 0 0-.217.068l-.92.9a25 25 0 0 1-1.871-.183.25.25 0 0 0-.068.495c.55.076 1.232.149 2.02.193a.25.25 0 0 0 .189-.071l.754-.736.847 1.71a.25.25 0 0 0 .404.062l.932-.97a25 25 0 0 1 1.922-.188.25.25 0 0 0-.068-.495c-.538.074-1.207.145-1.98.189a.25.25 0 0 0-.166.076l-.754.785-.842-1.7a.25.25 0 0 0-.182-.135'/><path d='M8.5 1.866a1 1 0 1 0-1 0V3h-2A4.5 4.5 0 0 0 1 7.5V8a1 1 0 0 0-1 1v2a1 1 0 0 0 1 1v1a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2v-1a1 1 0 0 0 1-1V9a1 1 0 0 0-1-1v-.5A4.5 4.5 0 0 0 10.5 3h-2zM14 7.5V13a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V7.5A3.5 3.5 0 0 1 5.5 4h5A3.5 3.5 0 0 1 14 7.5'/></svg>">
    
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/static/style.css">
</head>
<body>
    <!-- Auth Container -->
    <div id="auth-container" class="container mt-5">
        <!-- Login Form -->
        <div id="login-form">
            <h2>Sisteme Giriş</h2>
            <form id="login-form-element">
                <div class="mb-3">
                    <label for="login-email" class="form-label">E-posta</label>
                    <input type="email" class="form-control" id="login-email" required>
                </div>
                <div class="mb-3">
                    <label for="login-password" class="form-label">Şifre</label>
                    <input type="password" class="form-control" id="login-password" required>
                </div>
                <button type="submit" class="btn btn-primary">Giriş Yap</button>
                <button type="button" class="btn btn-link" id="show-register">Hesabınız yok mu? Kayıt Olun</button>
            </form>
        </div>

        <!-- Register Form -->
        <div id="register-form" style="display: none;">
            <h2>Yeni Kayıt</h2>
            <form id="register-form-element">
                <div class="mb-3">
                    <label for="register-email" class="form-label">E-posta</label>
                    <input type="email" class="form-control" id="register-email" required>
                </div>
                <div class="mb-3">
                    <label for="register-username" class="form-label">Kullanıcı Adı</label>
                    <input type="text" class="form-control" id="register-username" required>
                </div>
                <div class="mb-3">
                    <label for="register-password" class="form-label">Şifre</label>
                    <input type="password" class="form-control" id="register-password" required>
                </div>
                <button type="submit" class="btn btn-primary">Kayıt Ol</button>
                <button type="button" class="btn btn-link" id="show-login">Zaten hesabınız var mı? Giriş Yapın</button>
            </form>
        </div>
    </div>

    <!-- Main Container - Başlangıçta gizli olacak -->
    <div id="main-container" style="display: none;">
        <!-- Header -->
        <nav class="navbar navbar-expand-lg navbar-light bg-white border-bottom">
            <div class="container-fluid">
                <a class="navbar-brand" href="#">
                    <i class="bi bi-robot"></i> Çevre Bakanlığı Asistanı
                </a>
                <div class="ms-auto d-flex align-items-center">
                    <div class="dropdown">
                        <button class="btn btn-link text-dark" type="button" id="settingsDropdown" data-bs-toggle="dropdown">
                            <i class="bi bi-gear-fill"></i>
                        </button>
                        <ul class="dropdown-menu dropdown-menu-end">
                            <li><a class="dropdown-item" href="#"><i class="bi bi-question-circle"></i> Yardım</a></li>
                            <li><a class="dropdown-item" href="#"><i class="bi bi-book"></i> Dokümantasyon</a></li>
                            <li><hr class="dropdown-divider"></li>
                                    <div class="d-flex">
            <button id="logout-button" class="btn btn-outline-danger">
                <i class="bi bi-box-arrow-right"></i> Çıkış Yap
            </button>
        </div>
                        </ul>
                    </div>
                    <button id="new-chat-button" class="btn btn-outline-primary ms-2">
                        <i class="bi bi-plus-circle me-1"></i>
                        Yeni Sohbet
                    </button>
                </div>
            </div>
        </nav>

        <!-- Main Container -->
        <div class="d-flex h-100">
            <!-- Sidebar -->
            <div class="sidebar bg-light border-end">
                <div class="p-3">
                    <div class="d-flex justify-content-between align-items-center mb-3">
                        <h6 class="mb-0">Uzman Asistanlar</h6>
                        <button class="btn btn-sm btn-primary" data-bs-toggle="modal" data-bs-target="#createAssistantModal">
                            <i class="bi bi-plus"></i> Yeni
                        </button>
                    </div>
                    <select id="assistant-select" class="form-select mb-4">
                        <option value="">Bir asistan seçin...</option>
                    </select>

                    <!-- Conversations List -->
                    <div class="mt-4">
                        <div class="d-flex justify-content-between align-items-center mb-3">
                            <h6 class="mb-0">Geçmiş Sohbetler</h6>
                            <button id="load-conversations" class="btn btn-sm btn-outline-primary">
                                <i class="bi bi-arrow-clockwise"></i>
                            </button>
                        </div>
                        <div id="conversations-list" class="small overflow-auto" style="max-height: 300px;">
                            <!-- Konuşmalar buraya yüklenecek -->
                        </div>
                    </div>

                    <!-- File Manager Section -->
                    <div class="mt-4">
                        <h6 class="mb-3">Belge Yönetimi</h6>
                        <div class="file-drop-zone p-3 border rounded text-center mb-3">
                            <i class="bi bi-cloud-upload display-6"></i>
                            <p class="small mb-0">Dosyaları buraya sürükleyin<br>veya yüklemek için tıklayın</p>
                        </div>
                        <div class="file-list small">
                            <!-- Dosyalar burada listelenecek -->
                        </div>
                    </div>
                </div>
            </div>

            <!-- Main Chat Area -->
            <div class="main-content">
                <div class="chat-container d-flex flex-column">
                    <!-- Chat Header -->
                    <div class="chat-header border-bottom p-3">
                        <h5 class="mb-0" id="current-assistant">Sohbet başlatmak için bir asistan seçin</h5>
                    </div>

                    <!-- Messages Area -->
                    <div class="messages-area flex-grow-1 p-3" id="chat-messages">
                        <!-- Mesajlar burada görünecek -->
                    </div>

                    <!-- Input Area -->
                    <div class="chat-input-area border-top p-3">
                        <div class="input-group">
                            <input type="text" id="message-input" class="form-control" placeholder="Mesajınızı yazın...">
                            <button id="send-button" class="btn btn-primary">
                                <i class="bi bi-send"></i>
                            </button>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Create Assistant Modal -->
        <div class="modal fade" id="createAssistantModal" tabindex="-1" role="dialog" aria-labelledby="createAssistantModalLabel">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="modal-header">
                        <h5 class="modal-title">Yeni Asistan Oluştur</h5>
                        <button type="button" class="btn-close" data-bs-dismiss="modal"></button>
                    </div>
                    <div class="modal-body">
                        <form id="create-assistant-form">
                            <!-- Assistant Name -->
                            <div class="mb-3">
                                <label for="assistant-name" class="form-label">Asistan Adı</label>
                                <input type="text" class="form-control" id="assistant-name" required>
                            </div>

                            <!-- Model Type -->
                            <div class="mb-3">
                                <label for="model-type" class="form-label">Sağlayıcı</label>
                                <select class="form-select" id="model-type" required>
                                    <option value="">Sağlayıcı seçin...</option>
                                    <option value="openai">OpenAI</option>
                                    <option value="ollama">Ollama</option>
                                </select>
                            </div>

                            <!-- Model Name -->
                            <div class="mb-3">
                                <label for="model-name" class="form-label">Model</label>
                                <select class="form-select" id="model-name" required>
                                    <option value="">Bir model seçin...</option>
                                </select>
                            </div>

                            <!-- System Message -->
                            <div class="mb-3">
                                <label for="system-message" class="form-label">Sistem Mesajı</label>
                                <textarea class="form-control" id="system-message" rows="4" required></textarea>
                                <div class="form-text">Asistanın davranışını ve rolünü tanımlayın</div>
                            </div>

                            <!-- Model Parameters -->
                            <div class="border rounded p-3 mb-3">
                                <h6 class="mb-3">Model Parametreleri</h6>
                                
                                <!-- Temperature -->
                                <div class="mb-3">
                                    <label for="temperature" class="form-label d-flex justify-content-between">
                                        <span>Rastgelelik</span>
                                        <span class="text-muted" id="temperature-value">0.7</span>
                                    </label>
                                    <input type="range" class="form-range" id="temperature" 
                                           min="0" max="1" step="0.1" value="0.7">
                                    <div class="form-text">Rastgelelik: Düşük değerler cevapları daha odaklı, yüksek değerler daha yaratıcı yapar.</div>
                                </div>

                                <!-- Top P -->
                                <div class="mb-3">
                                    <label for="top-p" class="form-label d-flex justify-content-between">
                                        <span>Top P (Nükleus Örnekleme)</span>
                                        <span class="text-muted" id="top-p-value">0.9</span>
                                    </label>
                                    <input type="range" class="form-range" id="top-p" 
                                           min="0" max="1" step="0.1" value="0.9">
                                    <div class="form-text">Dikkate alınan token'ların kümülatif olasılığını sınırlar. Düşük değerler çıktıyı daha odaklı yapar.</div>
                                </div>

                                <!-- Max Tokens -->
                                <div class="mb-3">
                                    <label for="max-tokens" class="form-label d-flex justify-content-between">
                                        <span>Maksimum Token</span>
                                        <span class="text-muted" id="max-tokens-value">2000</span>
                                    </label>
                                    <input type="range" class="form-range" id="max-tokens" 
                                           min="100" max="4000" step="100" value="2000">
                                    <div class="form-text">Maksimum yanıt uzunluğu</div>
                                </div>

                                <!-- Frequency Penalty -->
                                <div class="mb-3">
                                    <label for="frequency-penalty" class="form-label d-flex justify-content-between">
                                        <span>Tekrar Cezası</span>
                                        <span class="text-muted" id="frequency-penalty-value">0.0</span>
                                    </label>
                                    <input type="range" class="form-range" id="frequency-penalty" 
                                           min="-2" max="2" step="0.1" value="0">
                                    <div class="form-text">Tekrarları azaltır. Yüksek değerler tekrarı azaltır.</div>
                                </div>

                                <!-- Presence Penalty -->
                                <div class="mb-3">
                                    <label for="presence-penalty" class="form-label d-flex justify-content-between">
                                        <span>Çeşitlilik Teşviki</span>
                                        <span class="text-muted" id="presence-penalty-value">0.0</span>
                                    </label>
                                    <input type="range" class="form-range" id="presence-penalty" 
                                           min="-2" max="2" step="0.1" value="0">
                                    <div class="form-text">Yeni konuları tartışmayı teşvik eder. Yüksek değerler konu çeşitliliğini artırır.</div>
                                </div>
                            </div>
                        </form>
                    </div>
                    <div class="modal-footer">
                        <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">İptal</button>
                        <button type="button" class="btn btn-primary" id="create-assistant-btn">Asistan Oluştur</button>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Scripts -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
    <script src="/static/app.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', () => {
            window.chatApp = new ChatApp();
        });
    </script>
</body>
</html>


==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\frontend\style.css ====
:root {
    --header-height: 60px;
    --sidebar-width: 300px;
    --primary-color: #0d6efd;
    --chat-bg: #f8f9fa;
    --user-msg-bg: #0d6efd;
    --assistant-msg-bg: #ffffff;
    --border-color: #dee2e6;
}

body {
    height: 100vh;
    margin: 0;
    overflow: hidden;
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
}

/* Header */
.navbar {
    height: var(--header-height);
    box-shadow: 0 2px 4px rgba(0,0,0,0.05);
}

/* Sidebar */
.sidebar {
    width: var(--sidebar-width);
    height: calc(100vh - var(--header-height));
    overflow-y: auto;
    background: #fff;
}

/* Main Content */
.main-content {
    flex: 1;
    height: calc(100vh - var(--header-height));
    background: var(--chat-bg);
}

.chat-container {
    height: 100%;
    display: flex;
    flex-direction: column;
}

/* Messages Area */
.messages-area {
    flex: 1;
    overflow-y: auto;
    padding: 2rem;
    background-color: var(--chat-bg);
}

/* Message Bubbles */
.message {
    max-width: 80%;
    margin-bottom: 1.5rem;
    padding: 1rem 1.25rem;
    border-radius: 1rem;
    position: relative;
    font-size: 0.95rem;
    line-height: 1.5;
    box-shadow: 0 2px 5px rgba(0,0,0,0.05);
}

.message.user {
    margin-left: auto;
    background-color: var(--user-msg-bg);
    color: white;
    border-bottom-right-radius: 0.25rem;
}

.message.assistant {
    margin-right: auto;
    background-color: var(--assistant-msg-bg);
    color: #2c3e50;
    border: 1px solid #e9ecef;
    border-bottom-left-radius: 0.25rem;
}

/* Input Area */
.chat-input-area {
    padding: 1rem 1.5rem;
    background: #fff;
    border-top: 1px solid var(--border-color);
}

.chat-input-area .input-group {
    box-shadow: 0 2px 6px rgba(0,0,0,0.05);
    border-radius: 0.5rem;
    overflow: hidden;
}

#message-input {
    border: 1px solid #e9ecef;
    padding: 0.75rem 1rem;
    font-size: 0.95rem;
    border-right: none;
}

#message-input:focus {
    box-shadow: none;
    border-color: var(--primary-color);
}

#send-button {
    padding: 0.75rem 1.5rem;
    font-size: 1rem;
}

/* File Drop Zone */
.file-drop-zone {
    background-color: #f8f9fa;
    border: 2px dashed #dee2e6;
    transition: all 0.3s ease;
    cursor: pointer;
}

.file-drop-zone.drag-over {
    border-color: #0d6efd;
    background-color: rgba(13, 110, 253, 0.1);
}

.file-item {
    background-color: white;
    transition: transform 0.2s;
}

.file-item:hover {
    transform: translateX(5px);
}

/* Scrollbar */
::-webkit-scrollbar {
    width: 6px;
}

::-webkit-scrollbar-track {
    background: #f1f1f1;
}

::-webkit-scrollbar-thumb {
    background: #c1c1c1;
    border-radius: 3px;
}

::-webkit-scrollbar-thumb:hover {
    background: #a8a8a8;
}

/* Chat Header */
.chat-header {
    padding: 1rem 1.5rem;
    background: #fff;
    border-bottom: 1px solid var(--border-color);
}

.chat-header h5 {
    color: #2c3e50;
    font-weight: 600;
}

/* Responsive */
@media (max-width: 768px) {
    .sidebar {
        position: fixed;
        left: -100%;
        z-index: 1000;
        transition: left 0.3s ease;
    }

    .sidebar.show {
        left: 0;
    }

    .message {
        max-width: 90%;
    }
}

/* Assistant Select */
#assistant-select {
    border: 1px solid #e9ecef;
    padding: 0.75rem;
    font-size: 0.95rem;
    border-radius: 0.5rem;
    background-color: #fff;
    box-shadow: 0 2px 4px rgba(0,0,0,0.05);
}

#assistant-select:focus {
    border-color: var(--primary-color);
    box-shadow: 0 0 0 0.2rem rgba(13, 110, 253, 0.25);
}

/* Toast Notifications */
.toast {
    border-radius: 0.5rem;
    box-shadow: 0 4px 12px rgba(0,0,0,0.15);
}

/* Conversation list styles */
.conversation-item {
    padding: 0.5rem;
    border-bottom: 1px solid #dee2e6;
    transition: background-color 0.2s;
}

.conversation-item:hover {
    background-color: #f8f9fa;
}

.conversation-item .btn-group {
    display: none;
}

.conversation-item:hover .btn-group {
    display: flex;
}

#conversations-list {
    scrollbar-width: thin;
    scrollbar-color: #888 #f1f1f1;
}

#conversations-list::-webkit-scrollbar {
    width: 6px;
}

#conversations-list::-webkit-scrollbar-track {
    background: #f1f1f1;
}

#conversations-list::-webkit-scrollbar-thumb {
    background: #888;
    border-radius: 3px;
}

#conversations-list::-webkit-scrollbar-thumb:hover {
    background: #555;
}


==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\frontend\static\style.css ====
/* ... mevcut stiller ... */

/* Conversation list styles */
.conversation-item {
    padding: 0.5rem;
    border-bottom: 1px solid #dee2e6;
    transition: background-color 0.2s ease;
    cursor: pointer;
    border-left: 3px solid transparent;
}

.conversation-item:hover {
    background-color: #f8f9fa;
    border-left-color: #0d6efd;
}

.conversation-item .btn-group {
    display: none;
}

.conversation-item:hover .btn-group {
    display: flex;
}

#conversations-list {
    scrollbar-width: thin;
    scrollbar-color: #888 #f1f1f1;
}

#conversations-list::-webkit-scrollbar {
    width: 6px;
}

#conversations-list::-webkit-scrollbar-track {
    background: #f1f1f1;
}

#conversations-list::-webkit-scrollbar-thumb {
    background: #888;
    border-radius: 3px;
}

#conversations-list::-webkit-scrollbar-thumb:hover {
    background: #555;
}

.conversation-info {
    flex-grow: 1;
    min-width: 0; /* text-truncate'in çalışması için */
    margin-right: 10px;
}

/* Hover efekti */
.hover-bg-light:hover {
    background-color: rgba(13, 110, 253, 0.05) !important;
}

/* Load Chat butonu */
.load-chat {
    white-space: nowrap;
    transition: all 0.2s ease;
}

.load-chat:hover {
    transform: translateX(2px);
} 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\routers\assistants.py ====
from fastapi import APIRouter, HTTPException, Depends
from fastapi.responses import StreamingResponse
from typing import List, AsyncGenerator, Optional, Dict
from sqlalchemy import select, delete, and_
from sqlalchemy.ext.asyncio import AsyncSession
from core.database.models import Assistant as AssistantModel, Conversation, Message, User
from core.database import get_db
from api.schemas import AssistantResponse, AssistantCreate, ConversationResponse, MessageResponse
from core.services.openai_service import OpenAIService
from core.services.ollama_service import OllamaService
from core.models.assistant import Assistant as AssistantClass
from api.dependencies import get_current_user
import uuid
from datetime import datetime
from sse_starlette.sse import EventSourceResponse
import asyncio
import json
from sqlalchemy.exc import IntegrityError

# Global (in-memory) Assistants Dictionary
assistants: Dict[str, AssistantClass] = {}

router = APIRouter(
    prefix="/assistants",
    tags=["assistants"]
)


@router.get("/list", response_model=List[AssistantResponse])
async def list_assistants(
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """Veritabanındaki tüm asistanları listeler."""
    try:
        print(f"Fetching assistants for user: {current_user.id}")
        query = select(AssistantModel)
        result = await db.execute(query)
        db_assistants = result.scalars().all()
        return [AssistantResponse.from_orm(assistant) for assistant in db_assistants]
    except Exception as e:
        print(f"Error in list_assistants: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/{assistant_name}/chat/stream")
async def chat_stream(
    assistant_name: str,
    message: str,
    conversation_id: Optional[str] = None,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    Streaming endpoint (SSE) ile asistan sohbeti.
    conversation_id verilirse o konuşmaya devam eder,
    verilmezse yeni bir Conversation kaydı oluşturur.
    """
    try:
        # 1. Asistanı DB'den bul
        query = select(AssistantModel).where(AssistantModel.name == assistant_name)
        result = await db.execute(query)
        db_assistant = result.scalar_one_or_none()
        if not db_assistant:
            raise HTTPException(status_code=404, detail="Assistant not found")

        # 2. Mevcut conversation varsa bul
        if conversation_id:
            conv_query = select(Conversation).where(
                and_(
                    Conversation.id == conversation_id,
                    Conversation.user_id == current_user.id
                )
            )
            conv_result = await db.execute(conv_query)
            conversation = conv_result.scalar_one_or_none()
            if not conversation:
                raise HTTPException(status_code=404, detail="Conversation not found")
        else:
            # conversation_id yok => yeni bir conversation başlat
            conversation = Conversation(
                id=str(uuid.uuid4()),
                name=f"Chat with {assistant_name}",
                assistant_id=db_assistant.id,
                session_id=str(uuid.uuid4()),
                user_id=current_user.id,
                created_at=datetime.utcnow()
            )
            db.add(conversation)
            await db.commit()
            await db.refresh(conversation)

        # 3. Kullanıcı mesajını DB'ye kaydet
        user_message = Message(
            id=str(uuid.uuid4()),
            conversation_id=conversation.id,
            role="user",
            content=message,
            created_at=datetime.utcnow()
        )
        db.add(user_message)
        await db.commit()

        # 4. Bellekte asistan var mı? Yoksa oluştur.
        if assistant_name not in assistants:
            config = db_assistant.config if isinstance(db_assistant.config, dict) else {}
            if db_assistant.model_type == "openai":
                model = OpenAIService(model=db_assistant.model_name)
            elif db_assistant.model_type == "ollama":
                model = OllamaService(model=db_assistant.model_name)
            else:
                raise HTTPException(status_code=400, detail="Invalid model type")

            new_assistant = AssistantClass(
                name=db_assistant.name,
                model=model,
                system_message=db_assistant.system_message,
                config=config
            )
            assistants[assistant_name] = new_assistant

        # 5. Yanıtı stream şeklinde döndüren generator
        async def generate() -> AsyncGenerator[str, None]:
            full_response = ""
            try:
                # Asistan objesini memory'den al
                current_assistant = assistants[assistant_name]

                # Asistan yanıtını parça parça al
                async for chunk in current_assistant.process_message(message, stream=True):
                    if chunk:
                        full_response += chunk
                        yield f"data: {chunk}\n\n"

                # Yanıt tamamlanınca asistan mesajını kaydet
                if full_response:
                    assistant_message = Message(
                        id=str(uuid.uuid4()),
                        conversation_id=conversation.id,
                        role="assistant",
                        content=full_response,
                        created_at=datetime.utcnow()
                    )
                    db.add(assistant_message)
                    await db.commit()

                yield "data: [DONE]\n\n"

            except Exception as e:
                error_msg = f"Stream generation error: {str(e)}"
                print(error_msg)

                # Hata mesajını DB'ye de kaydedebiliriz
                error_message = Message(
                    id=str(uuid.uuid4()),
                    conversation_id=conversation.id,
                    role="assistant",
                    content=f"Error: {str(e)}",
                    created_at=datetime.utcnow()
                )
                db.add(error_message)
                await db.commit()

                yield f"data: error: {str(e)}\n\n"

        # 6. SSE response
        return StreamingResponse(
            generate(),
            media_type="text/event-stream",
            headers={
                "X-Conversation-Id": str(conversation.id),
                "Cache-Control": "no-cache"
            }
        )

    except Exception as e:
        print(f"Chat stream error: {str(e)}")
        await db.rollback()
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/create", response_model=AssistantResponse)
async def create_assistant(
    assistant: AssistantCreate,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    try:
        # Model servisini oluştur
        if assistant.model_type == "openai":
            model_service = OpenAIService(model=assistant.model_name)
        elif assistant.model_type == "ollama":
            model_service = OllamaService(model=assistant.model_name)
        else:
            raise HTTPException(status_code=400, detail="Invalid model type")
        
        # Veritabanına kaydet
        db_assistant = AssistantModel(
            id=str(uuid.uuid4()),
            name=assistant.name,
            model_type=assistant.model_type,
            model_name=assistant.model_name,
            system_message=assistant.system_message,
            config=assistant.config,
            creator_id=current_user.id
        )
        db.add(db_assistant)
        await db.commit()
        await db.refresh(db_assistant)
        
        # Asistanı memory'ye ekle
        new_assistant = AssistantClass(
            name=assistant.name,
            model=model_service,
            system_message=assistant.system_message,
            config=assistant.config
        )
        assistants[assistant.name] = new_assistant
        
        return db_assistant
        
    except IntegrityError as e:
        await db.rollback()
        raise HTTPException(
            status_code=409,
            detail="Assistant name already exists"
        )
    except Exception as e:
        await db.rollback()
        print(f"Error creating assistant: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to create assistant: {str(e)}"
        )


@router.get("/conversations", response_model=List[ConversationResponse])
async def get_conversations(
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user),
    skip: int = 0,
    limit: int = 10
):
    """Mevcut kullanıcının konuşmalarını listeler."""
    try:
        print(f"Fetching conversations for user: {current_user.id}")
        query = (
            select(Conversation)
            .where(Conversation.user_id == current_user.id)
            .order_by(Conversation.created_at.desc())
            .offset(skip)
            .limit(limit)
        )
        result = await db.execute(query)
        conversations = result.scalars().all()

        response_list = []
        for conv in conversations:
            # Konuşmaya ait mesajları al
            messages_query = select(Message).where(Message.conversation_id == conv.id)
            messages_result = await db.execute(messages_query)
            messages = messages_result.scalars().all()

            # Asistanı bul
            assistant_query = select(AssistantModel).where(AssistantModel.id == conv.assistant_id)
            assistant_result = await db.execute(assistant_query)
            db_assistant = assistant_result.scalar_one_or_none()

            response_list.append(
                ConversationResponse(
                    id=conv.id,
                    name=conv.name,
                    assistant_id=conv.assistant_id,
                    assistant_name=db_assistant.name if db_assistant else "Unknown",
                    session_id=conv.session_id,
                    user_id=conv.user_id,
                    created_at=conv.created_at,
                    messages=[MessageResponse.from_orm(msg) for msg in messages]
                )
            )

        return response_list

    except Exception as e:
        print(f"Error fetching conversations: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/conversations/{conversation_id}/messages", response_model=List[MessageResponse])
async def get_conversation_messages(
    conversation_id: str,
    db: AsyncSession = Depends(get_db)
):
    """Belirli bir konuşmadaki tüm mesajları döndürür."""
    try:
        query = select(Message).where(
            Message.conversation_id == conversation_id
        ).order_by(Message.created_at.asc())

        result = await db.execute(query)
        messages = result.scalars().all()
        return messages

    except Exception as e:
        print(f"Error getting messages: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/conversations/{conversation_id}")
async def delete_conversation(
    conversation_id: str,
    db: AsyncSession = Depends(get_db)
):
    """Belirli bir konuşmayı siler (mesajlarıyla birlikte)."""
    try:
        # Önce mesajları sil
        await db.execute(
            delete(Message).where(Message.conversation_id == conversation_id)
        )
        # Sonra konuşmayı sil
        result = await db.execute(
            delete(Conversation).where(Conversation.id == conversation_id)
        )
        await db.commit()

        if result.rowcount == 0:
            raise HTTPException(status_code=404, detail="Conversation not found")

        return {"message": "Conversation deleted successfully"}

    except HTTPException as he:
        raise he
    except Exception as e:
        print(f"Error deleting conversation: {str(e)}")
        await db.rollback()
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/models", response_model=Dict[str, List[str]])
async def list_models(current_user: User = Depends(get_current_user)):
    """OpenAI ve Ollama modellerini listeler."""
    try:
        openai_service = OpenAIService()
        ollama_service = OllamaService()

        openai_models = await openai_service.list_models()
        ollama_models = await ollama_service.list_models()

        return {
            "openai": openai_models,
            "ollama": ollama_models
        }

    except Exception as e:
        print(f"Error in list_models: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to fetch models: {str(e)}"
        )


==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\routers\auth.py ====
from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from datetime import datetime, timedelta
from jose import JWTError, jwt
from passlib.context import CryptContext
from core.database import get_db
from core.database.models import User
from api.schemas import UserCreate, UserResponse, Token
import os
from dotenv import load_dotenv

load_dotenv()

router = APIRouter(
    prefix="/auth",
    tags=["auth"]
)

# Güvenlik ayarları
SECRET_KEY = os.getenv("SECRET_KEY", "your-secret-key")
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 30

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="auth/token")

# Yardımcı fonksiyonlar
def verify_password(plain_password, hashed_password):
    return pwd_context.verify(plain_password, hashed_password)

def get_password_hash(password):
    return pwd_context.hash(password)

def create_access_token(data: dict):
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

# Auth endpoints
@router.post("/register", response_model=UserResponse)
async def register(user: UserCreate, db: AsyncSession = Depends(get_db)):
    # Email kontrolü
    query = select(User).where(User.email == user.email)
    result = await db.execute(query)
    if result.scalar_one_or_none():
        raise HTTPException(
            status_code=400,
            detail="Email already registered"
        )
    
    # Yeni kullanıcı oluştur
    hashed_password = get_password_hash(user.password)
    db_user = User(
        email=user.email,
        username=user.username,
        hashed_password=hashed_password,
        created_at=datetime.utcnow()
    )
    
    db.add(db_user)
    await db.commit()
    await db.refresh(db_user)
    
    return db_user

@router.post("/token", response_model=Token)
async def login(
    form_data: OAuth2PasswordRequestForm = Depends(),
    db: AsyncSession = Depends(get_db)
):
    try:
        print(f"Login attempt for email: {form_data.username}")
        
        # Kullanıcıyı bul
        query = select(User).where(User.email == form_data.username)
        result = await db.execute(query)
        user = result.scalar_one_or_none()
        
        print(f"User found: {user is not None}")
        
        if not user or not verify_password(form_data.password, user.hashed_password):
            print("Invalid credentials")
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Incorrect email or password",
                headers={"WWW-Authenticate": "Bearer"},
            )
        
        # Token oluştur
        access_token = create_access_token(
            data={"sub": user.email}
        )
        
        print("Login successful, token created")
        return {"access_token": access_token, "token_type": "bearer"}
        
    except Exception as e:
        print(f"Login error: {str(e)}")
        print(f"Error type: {type(e)}")
        import traceback
        print(f"Traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/logout")
async def logout():
    return {"message": "Successfully logged out"}

# Dependency for protected routes
async def get_current_user(
    token: str = Depends(oauth2_scheme),
    db: AsyncSession = Depends(get_db)
) -> User:
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )
    
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        email: str = payload.get("sub")
        if email is None:
            raise credentials_exception
    except JWTError:
        raise credentials_exception
    
    query = select(User).where(User.email == email)
    result = await db.execute(query)
    user = result.scalar_one_or_none()
    
    if user is None:
        raise credentials_exception
    
    return user 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\routers\documents.py ====
from fastapi import APIRouter, Depends, UploadFile, File, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from typing import List
import uuid

from core.database import get_db, AsyncSessionLocal
from core.database.models import RAGDocument
from core.schemas.enums import FileType
from core.services.file_upload import FileUploadService
from core.services.document_processing import DocumentProcessor
from api.dependencies import get_current_user
from api.schemas import RAGDocumentResponse
from core.database.crud import create_rag_document

router = APIRouter(
    prefix="/documents",
    tags=["documents"]
)

@router.post("/upload", response_model=RAGDocumentResponse)
async def upload_document(
    file: UploadFile = File(...),
    current_user = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    try:
        # 1. Dosya validasyonu
        if not file.filename.lower().endswith(('.pdf', '.docx', '.txt', '.md')):
            raise HTTPException(400, "Desteklenmeyen dosya formatı")
        print(file.filename)
        # 2. Dosyayı geçici klasöre kaydet
        upload_service = FileUploadService()
        upload_data = await upload_service.save_temp_file(file, current_user)
        print("upload_data::", upload_data)
        processor = DocumentProcessor()
        print("upload_data['temp_path']::", upload_data["temp_path"])
        doc_record = await processor.process_document(upload_data["temp_path"],upload_data["content"], current_user.id)
        print(doc_record)

        document_data = {
            "title": upload_data["original_name"],
            "content": upload_data["content"],
            "file_path": upload_data["temp_path"],
            "file_type": upload_data["file_type"],
            "user_id": current_user.id
        }
        
        new_doc = await create_rag_document(db, document_data)
        return new_doc

    except HTTPException as he:
        raise he
    except Exception as e:
        raise HTTPException(500, f"Dosya işleme hatası: {str(e)}")

@router.get("/", response_model=List[RAGDocumentResponse])
async def list_user_documents(
    db: AsyncSession = Depends(get_db),
    current_user = Depends(get_current_user),
):
    try:
        processor = DocumentProcessor(db)
        docs = await processor.get_user_documents(current_user.id)
        return docs
    except Exception as e:
        raise HTTPException(500, f"Dökümanlar getirilemedi: {str(e)}") 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\routers\rag.py ====
from fastapi import APIRouter, Depends, HTTPException
from typing import List

from api.schemas import RAGConfig
from api.dependencies import get_assistant
from core.rag.simple_rag import SimpleRAG

router = APIRouter(
    prefix="/rag",
    tags=["rag"]
)

@router.post("/{assistant_name}/add")
async def add_rag_to_assistant(
    assistant_name: str,
    rag_config: RAGConfig,
    documents: dict,
    assistant = Depends(get_assistant)
):
    rag_system = SimpleRAG(rag_config.name, documents)
    assistant.add_rag_system(
        rag_system,
        name=rag_config.name,
        weight=rag_config.weight,
        enabled=rag_config.enabled
    )
    return {"message": f"RAG system {rag_config.name} added to assistant {assistant_name}"}

@router.post("/{assistant_name}/{rag_name}/toggle")
async def toggle_rag_system(
    assistant_name: str,
    rag_name: str,
    enable: bool,
    assistant = Depends(get_assistant)
):
    if enable:
        assistant.enable_rag_system(rag_name)
    else:
        assistant.disable_rag_system(rag_name)
    return {"message": f"RAG system {rag_name} {'enabled' if enable else 'disabled'}"} 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\routers\__init__.py ====
from .assistants import router as assistants_router
from .rag import router as rag_router
from .documents import router as documents_router

__all__ = [
    "assistants_router",
    "rag_router",
    "documents_router", 
] 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\scripts\check_tables.py ====
import asyncio
import asyncpg
from dotenv import load_dotenv
import os
import sys
from pathlib import Path

# Proje kök dizinini Python path'ine ekle
project_root = str(Path(__file__).parent.parent)
sys.path.append(project_root)

async def check_tables():
    load_dotenv()
    
    # Database credentials
    DB_NAME = os.getenv("DB_NAME", "chatbot")
    DB_USER = os.getenv("DB_USER", "postgres")
    DB_PASSWORD = os.getenv("DB_PASSWORD", "**Malatya44")
    DB_HOST = os.getenv("DB_HOST", "localhost")
    DB_PORT = os.getenv("DB_PORT", "5432")
    
    try:
        # Database'e bağlan
        conn = await asyncpg.connect(
            user=DB_USER,
            password=DB_PASSWORD,
            host=DB_HOST,
            port=DB_PORT,
            database=DB_NAME
        )
        
        # Mevcut tabloları kontrol et
        tables = await conn.fetch("""
            SELECT table_name 
            FROM information_schema.tables 
            WHERE table_schema = 'public'
        """)
        
        print("\nMevcut tablolar:")
        for table in tables:
            print(f"- {table['table_name']}")
            
            # Her tablonun yapısını göster
            columns = await conn.fetch("""
                SELECT column_name, data_type, is_nullable
                FROM information_schema.columns
                WHERE table_name = $1
            """, table['table_name'])
            
            print("  Kolonlar:")
            for col in columns:
                nullable = "NULL" if col['is_nullable'] == 'YES' else 'NOT NULL'
                print(f"    - {col['column_name']}: {col['data_type']} {nullable}")
            print()
            
        await conn.close()
        
    except Exception as e:
        print(f"Error: {str(e)}")
        raise

if __name__ == "__main__":
    asyncio.run(check_tables()) 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\scripts\create_database.py ====
import asyncio
import asyncpg
from dotenv import load_dotenv
import os
import sys
from pathlib import Path

# Proje kök dizinini Python path'ine ekle
project_root = str(Path(__file__).parent.parent)
sys.path.append(project_root)

async def create_database():
    load_dotenv()
    
    # Database credentials
    DB_NAME = os.getenv("DB_NAME", "chatbot")
    DB_USER = os.getenv("DB_USER", "postgres")
    DB_PASSWORD = os.getenv("DB_PASSWORD", "**Malatya44")
    DB_HOST = os.getenv("DB_HOST", "localhost")
    DB_PORT = os.getenv("DB_PORT", "5432")
    
    try:
        # Önce default database'e bağlan
        conn = await asyncpg.connect(
            user=DB_USER,
            password=DB_PASSWORD,
            host=DB_HOST,
            port=DB_PORT,
            database='postgres'
        )
        
        # Database'i oluştur
        try:
            await conn.execute(f'CREATE DATABASE "{DB_NAME}"')
            print(f"Database '{DB_NAME}' created successfully!")
        except asyncpg.exceptions.DuplicateDatabaseError:
            print(f"Database '{DB_NAME}' already exists!")
            
        await conn.close()
        
        # Yeni database'e bağlan ve tabloları oluştur
        from core.database.session import init_db
        await init_db()
        
    except Exception as e:
        print(f"Error: {str(e)}")
        raise

if __name__ == "__main__":
    asyncio.run(create_database()) 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\scripts\recreate_tables.py ====
import asyncio
import asyncpg
from dotenv import load_dotenv
import os
import sys
from pathlib import Path

# Proje kök dizinini Python path'ine ekle
project_root = str(Path(__file__).parent.parent)
sys.path.append(project_root)

async def recreate_tables():
    load_dotenv()
    
    # Database credentials
    DB_NAME = os.getenv("DB_NAME", "chatbot")
    DB_USER = os.getenv("DB_USER", "postgres")
    DB_PASSWORD = os.getenv("DB_PASSWORD", "**Malatya44")
    DB_HOST = os.getenv("DB_HOST", "localhost")
    DB_PORT = os.getenv("DB_PORT", "5432")
    
    try:
        # Database'e bağlan
        conn = await asyncpg.connect(
            user=DB_USER,
            password=DB_PASSWORD,
            host=DB_HOST,
            port=DB_PORT,
            database=DB_NAME
        )
        
        # Tüm tabloları sil
        await conn.execute("""
            DROP TABLE IF EXISTS 
                rag_results, 
                messages, 
                conversations, 
                rag_systems, 
                assistants 
            CASCADE
        """)
        
        await conn.close()
        print("Existing tables dropped successfully!")
        
        # Tabloları yeniden oluştur
        from core.database.session import init_db
        await init_db()
        
    except Exception as e:
        print(f"Error: {str(e)}")
        raise

if __name__ == "__main__":
    asyncio.run(recreate_tables()) 

==== File: C:\Users\Tuga-Munir\source\repos\chatbot_framework\scripts\test_database.py ====
# Path: chatbot_framework/scripts/test_database.py
import asyncio
import sys
from pathlib import Path
from datetime import datetime
from sqlalchemy import select
from sqlalchemy.orm import selectinload
import random

# Proje kök dizinini Python path'ine ekle
project_root = str(Path(__file__).parent.parent)
sys.path.append(project_root)

from core.database.session import async_session
from core.database.models import Assistant, Conversation, Message, RAGSystem, RAGResult

async def test_database():
    try:
        async with async_session() as session:
            # 1. Asistan oluştur
            print("\n=== Creating Assistant ===")
            assistant_name = f"Test Assistant {random.randint(1000,9999)}"
            assistant = Assistant(
                name=assistant_name,
                model_type="openai",
                system_message="You are a helpful assistant.",
                config={"temperature": 0.7}
            )
            session.add(assistant)
            await session.commit()
            print(f"Assistant created with ID: {assistant.id}")

            # 2. RAG sistemi ekle
            print("\n=== Adding RAG System ===")
            rag_system = RAGSystem(
                assistant_id=assistant.id,
                name="Test RAG",
                weight=1.0,
                enabled=True,
                config={"source": "test_documents"}
            )
            session.add(rag_system)
            await session.commit()
            print(f"RAG System created with ID: {rag_system.id}")

            # 3. Konuşma başlat
            print("\n=== Starting Conversation ===")
            conversation = Conversation(
                assistant_id=assistant.id,
                session_id="test_session",
                user_id="test_user"
            )
            session.add(conversation)
            await session.commit()
            print(f"Conversation created with ID: {conversation.id}")

            # 4. Mesajlar ekle
            print("\n=== Adding Messages ===")
            # Kullanıcı mesajı
            user_message = Message(
                conversation_id=conversation.id,
                role="user",
                content="What is the meaning of life?"
            )
            session.add(user_message)
            await session.commit()
            print(f"User message created with ID: {user_message.id}")

            # Asistan mesajı
            assistant_message = Message(
                conversation_id=conversation.id,
                role="assistant",
                content="The meaning of life is 42."
            )
            session.add(assistant_message)
            await session.commit()
            print(f"Assistant message created with ID: {assistant_message.id}")

            # 5. RAG sonucu ekle
            print("\n=== Adding RAG Result ===")
            rag_result = RAGResult(
                message_id=assistant_message.id,
                rag_system_id=rag_system.id,
                context="Found in Hitchhiker's Guide to the Galaxy",
                meta_data={"confidence": 0.95}
            )
            session.add(rag_result)
            await session.commit()
            print(f"RAG Result created with ID: {rag_result.id}")

            # 6. Verileri kontrol et
            print("\n=== Checking Data ===")
            # Tüm ilişkili verileri tek seferde çek
            stmt = select(Assistant).where(Assistant.id == assistant.id).options(
                selectinload(Assistant.conversations).selectinload(Conversation.messages).selectinload(Message.rag_results)
            )
            result = await session.execute(stmt)
            db_assistant = result.scalar_one()

            print(f"\nAssistant: {db_assistant.name}")
            print(f"Model Type: {db_assistant.model_type}")
            print(f"System Message: {db_assistant.system_message}")
            
            # İlişkili verileri göster
            for conv in db_assistant.conversations:
                print(f"\nConversation ID: {conv.id}")
                print(f"Session ID: {conv.session_id}")
                print("\nMessages:")
                for msg in conv.messages:
                    print(f"- {msg.role}: {msg.content}")
                    if msg.rag_results:
                        for rag in msg.rag_results:
                            print(f"  RAG Context: {rag.context}")
                            print(f"  RAG Meta Data: {rag.meta_data}")

    except Exception as e:
        print(f"Error during database test: {str(e)}")
        import traceback
        print(traceback.format_exc())
        raise

if __name__ == "__main__":
    asyncio.run(test_database()) 

